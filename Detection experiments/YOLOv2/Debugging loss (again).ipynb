{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672fe8bc-308e-4197-b661-fe66c026cbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.23). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../../\")\n",
    "sys.path.insert(1, \"../../Models/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from yolov2 import YOLOv2D19 as YOLOv2\n",
    "from detection_datasets import VOCDatasetV2\n",
    "from torch import optim\n",
    "from train import *\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from data_preprocessing import get_norms\n",
    "import pickle\n",
    "from eval import evaluate, get_pred_boxes, get_gt_boxes, NMS\n",
    "with open('../../Models/anchors_VOC0712trainval.pickle', 'rb') as handle:\n",
    "    anchors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c918b344-032e-40fc-bd04-871815c8d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "\n",
    "class YOLOv2Loss(nn.Module):\n",
    "    def __init__(self, anchors, lambda_noobj=0.5, lambda_coord=5.0, lambda_isobj=1.0, lambda_class=1.0, num_classes=20):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss(reduction='mean')\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_isobj = lambda_isobj\n",
    "        self.lambda_class = lambda_class\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, out, gt_out):\n",
    "        # [conf, obj_xc, obj_yc, obj_w, obj_h]\n",
    "        is_obj = gt_out[:, 0::25, ...] == 1.0\n",
    "        no_obj = gt_out[:, 0::25, ...] == 0.0\n",
    "\n",
    "        # print(is_obj.shape)\n",
    "        # print(is_obj)\n",
    "\n",
    "        # CONFIDENCE LOSS ===========\n",
    "        # conf_true = gt_out[:, 0::25, ...]\n",
    "        # conf_pred = out[:, 0::25, ...].sigmoid()\n",
    "        # out[:, 0::25, ...] = out[:, 0::25, ...].sigmoid()\n",
    "\n",
    "        # is_obj_conf_pred = is_obj * conf_pred\n",
    "        # is_obj_conf_true = is_obj * conf_true\n",
    "        \n",
    "        \n",
    "        # no_obj_conf_pred = no_obj * conf_pred\n",
    "        # no_obj_conf_true = no_obj * conf_true\n",
    "\n",
    "        is_obj_conf_loss = self.mse(is_obj * out[:, 0::25, ...].sigmoid(), is_obj * gt_out[:, 0::25, ...])\n",
    "        no_obj_conf_loss = self.mse(no_obj * out[:, 0::25, ...].sigmoid(), no_obj * gt_out[:, 0::25, ...]) \n",
    "        # ===========================\n",
    "\n",
    "        # BOX LOSS ==================\n",
    "            # XCYC LOSS ==================\n",
    "        # xc_true = gt_out[:, 1::25, ...]\n",
    "        # yc_true = gt_out[:, 2::25, ...]\n",
    "\n",
    "        # xc_pred = out[:, 1::25, ...].sigmoid()\n",
    "        # yc_pred = out[:, 2::25, ...].sigmoid()\n",
    "\n",
    "        # xc_pred = is_obj * xc_pred\n",
    "        # xc_true = is_obj * xc_true\n",
    "        # yc_pred = is_obj * yc_pred\n",
    "        # yc_true = is_obj * yc_true\n",
    "\n",
    "        xc_loss = self.mse(is_obj * out[:, 1::25, ...].sigmoid(), is_obj * gt_out[:, 1::25, ...])\n",
    "        yc_loss = self.mse(is_obj * out[:, 2::25, ...].sigmoid(), is_obj * gt_out[:, 2::25, ...])\n",
    "            # ============================\n",
    "\n",
    "            # WH LOSS ====================\n",
    "        \n",
    "        # w_true = gt_out[:, 3::25, ...]\n",
    "        # h_true = gt_out[:, 4::25, ...]\n",
    "        \n",
    "        scale = gt_out.shape[-1]\n",
    "        _anchors = torch.tensor(self.anchors).to(out.device) * scale\n",
    "        pw = _anchors[:, 0]\n",
    "        ph = _anchors[:, 1]\n",
    "        \n",
    "        # w_pred = out[:, 3::25, ...]\n",
    "        # h_pred = out[:, 4::25, ...]\n",
    "\n",
    "        gt_out[:, 3::25, ...] = torch.log(\n",
    "                                1e-16 + gt_out[:, 3::25, ...] / pw[None, :, None, None]\n",
    "        )\n",
    "        gt_out[:, 4::25, ...] = torch.log(\n",
    "                                1e-16 + gt_out[:, 4::25, ...] / ph[None, :, None, None]\n",
    "        )\n",
    "        \n",
    "        # w_pred = is_obj * w_pred\n",
    "        # w_true = is_obj * w_true\n",
    "        # h_pred = is_obj * h_pred\n",
    "        # h_true = is_obj * h_true\n",
    "\n",
    "        w_loss = self.mse(is_obj * out[:, 3::25, ...], is_obj * gt_out[:, 3::25, ...])\n",
    "        h_loss = self.mse(is_obj * out[:, 4::25, ...], is_obj * gt_out[:, 4::25, ...])\n",
    "        \n",
    "            # ============================\n",
    "        # ===========================\n",
    "        \n",
    "        # CLASS LOSS ================\n",
    "        # class_true = []\n",
    "        # for i in range(len(self.anchors)):\n",
    "        #     first_idx = 5 + i*(5+self.num_classes)\n",
    "        #     last_idx = 25 + i*(5+self.num_classes)\n",
    "        #     class_true.append(gt_out[:, first_idx:last_idx, ...])\n",
    "        # class_true = torch.stack(class_true, dim=1)\n",
    "\n",
    "        # class_pred = []\n",
    "        # for i in range(len(self.anchors)):\n",
    "        #     first_idx = 5 + i*(5+self.num_classes)\n",
    "        #     last_idx = 25 + i*(5+self.num_classes)\n",
    "        #     class_pred.append(gt_out[:, first_idx:last_idx, ...])\n",
    "        # class_pred = torch.stack(class_pred, dim=1)\n",
    "\n",
    "        # class_pred = self.softmax(class_pred)\n",
    "        \n",
    "        # class_pred = is_obj[:, :, None, :, :] * class_pred\n",
    "        # class_true = is_obj[:, :, None, :, :] * class_true\n",
    "\n",
    "        # class_loss = self.mse(class_pred, class_true)\n",
    "        \n",
    "        class_loss = 0\n",
    "        for i in range(len(self.anchors)):\n",
    "            first_idx = 5 + i*(5+self.num_classes)\n",
    "            last_idx = 25 + i*(5+self.num_classes)\n",
    "            # print(is_obj.shape, self.softmax(out[:, first_idx:last_idx, ...]).shape)\n",
    "            class_loss += self.mse(is_obj[:, i, ...].unsqueeze(1).repeat(1, 20, 1, 1) * self.softmax(out[:, first_idx:last_idx, ...]), \n",
    "                                   is_obj[:, i, ...].unsqueeze(1).repeat(1, 20, 1, 1) * gt_out[:, first_idx:last_idx, ...])\n",
    "        # ===========================\n",
    "\n",
    "        loss =  \\\n",
    "                self.lambda_coord * (w_loss + h_loss) + \\\n",
    "                self.lambda_coord * (xc_loss + yc_loss) + \\\n",
    "                self.lambda_isobj * is_obj_conf_loss + \\\n",
    "                self.lambda_noobj * no_obj_conf_loss + \\\n",
    "                self.lambda_class * class_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60911266-7f4d-4d0c-8cf3-10164cacefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHORS = [\n",
    "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
    "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
    "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fcf93f-33f2-4aa3-acfd-15de3ed572cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "dtype=torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f03203-68f4-45b5-ad90-bca9bfa99586",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = get_norms('../../../datasets/VOCdevkit/trainval_norms.json')\n",
    "means = norms['means']\n",
    "stds = norms['stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c147311-b86b-419a-a1dd-baecd6fc864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ../../../datasets/VOCdevkit/VOC2012\\ImageSets\\Main\\trainval.txt\n",
      "True ../../../datasets/VOCdevkit/VOC2007\\ImageSets\\Main\\val.txt\n"
     ]
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(width=416, height=416),\n",
    "    # A.VerticalFlip(p=1.0),\n",
    "    A.Normalize(mean=means, std=stds),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "train_set = VOCDatasetV2(devkit_path = '../../../datasets/VOCdevkit/', \n",
    "                         subsets = [('VOC2012', 'trainval')],\n",
    "                         scales=[13], anchors=ANCHORS[0], transforms=transforms, \n",
    "                         dtype=dtype, device=device)\n",
    "val_set = VOCDatasetV2(devkit_path = '../../../datasets/VOCdevkit/', \n",
    "                       subsets = [('VOC2007', 'val')],\n",
    "                       scales=[13], anchors=ANCHORS[0], transforms=transforms, \n",
    "                       dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "057b4ebc-c87f-480f-9714-36051e551583",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Subset(train_set, list(range(0, 100)))\n",
    "val_set = Subset(val_set, list(range(1, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7f4eb2-0231-4e1c-9b4e-5d2d2eb4944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c1d133-b237-4200-865b-1fdb9e692aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Detection experiments\\YOLOv2\\../../Models\\yolov2.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "model = YOLOv2(state_dict_path='../../Models/darknet19_72.96.pth', num_anchors=3, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d4fde7-cfcf-4eae-b6c4-52cd8472ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.amp.GradScaler(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2bc4059-cc5a-42fa-b5c0-adb82f46f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YOLOv2Loss(anchors=ANCHORS[0], lambda_noobj=10, lambda_coord=10.0, lambda_isobj=1.0, lambda_class=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3b007d3-7e89-496a-8ba1-ccddffc40a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "355e8254-9094-47bb-b55a-2d82873cf530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1ec0b9b3520>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e3b8cb-2250-41d3-8870-062ae11f79fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 19:38:00.049528 Epoch 1 \n",
      "[Train] Loss per batch: 3.0123\n",
      "[Val] loss per batch: 2.4987\n",
      "Epoch 1: SGD lr 0.0000 -> 0.0000\n"
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, train_loader, model, optimizer, loss_fn, scheduler, scaler, \n",
    "                                save_grad=False, outputs_path='../log/YOLOv2/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deab2a9b-054a-4652-bbf4-fdf49c554720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utils import (\n",
    "    mean_average_precision,\n",
    "    cells_to_bboxes,\n",
    "    get_evaluation_bboxes,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    check_class_accuracy,\n",
    "    plot_couple_examples\n",
    ")\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1420c55-b3b5-4420-a2a7-b48a5ff77c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 13, 13, 4]) torch.Size([32, 3, 13, 13, 1])\n",
      "torch.Size([32, 3, 13, 13, 1])\n",
      "torch.Size([75, 13, 4]) torch.Size([75, 3, 13, 13, 1])\n",
      "torch.Size([75, 13, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (75) must match the size of tensor b (13) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_boxes, true_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mget_evaluation_bboxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNMS_IOU_THRESH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43manchors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANCHORS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONF_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m mapval \u001b[38;5;241m=\u001b[39m mean_average_precision(\n\u001b[0;32m      9\u001b[0m     pred_boxes,\n\u001b[0;32m     10\u001b[0m     true_boxes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_CLASSES,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapval\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Detection experiments\\YOLOv2\\_utils.py:334\u001b[0m, in \u001b[0;36mget_evaluation_bboxes\u001b[1;34m(loader, model, iou_threshold, anchors, threshold, box_format, device)\u001b[0m\n\u001b[0;32m    331\u001b[0m     gt_out \u001b[38;5;241m=\u001b[39m gt_out\u001b[38;5;241m.\u001b[39mreshape(batch_size, num_boxes \u001b[38;5;241m*\u001b[39m obj_stride, grid_size, grid_size)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# we just want one bbox for each label, not one for each scale\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m true_bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mcells_to_bboxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgt_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_preds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    336\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m    339\u001b[0m     nms_boxes \u001b[38;5;241m=\u001b[39m non_max_suppression(\n\u001b[0;32m    340\u001b[0m         bboxes[idx],\n\u001b[0;32m    341\u001b[0m         iou_threshold\u001b[38;5;241m=\u001b[39miou_threshold,\n\u001b[0;32m    342\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[0;32m    343\u001b[0m         box_format\u001b[38;5;241m=\u001b[39mbox_format,\n\u001b[0;32m    344\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Detection experiments\\YOLOv2\\_utils.py:394\u001b[0m, in \u001b[0;36mcells_to_bboxes\u001b[1;34m(predictions, anchors, S, is_preds)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mprint\u001b[39m(box_predictions\u001b[38;5;241m.\u001b[39mshape, cell_indices\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mprint\u001b[39m(box_predictions[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 394\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m S \u001b[38;5;241m*\u001b[39m (\u001b[43mbox_predictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcell_indices\u001b[49m)\n\u001b[0;32m    395\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m S \u001b[38;5;241m*\u001b[39m (box_predictions[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m cell_indices\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m    396\u001b[0m w_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m S \u001b[38;5;241m*\u001b[39m box_predictions[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (75) must match the size of tensor b (13) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "pred_boxes, true_boxes = get_evaluation_bboxes(\n",
    "                train_loader,\n",
    "                model,\n",
    "                iou_threshold=config.NMS_IOU_THRESH,\n",
    "                anchors=config.ANCHORS,\n",
    "                threshold=config.CONF_THRESHOLD,\n",
    "            )\n",
    "mapval = mean_average_precision(\n",
    "    pred_boxes,\n",
    "    true_boxes,\n",
    "    iou_threshold=config.MAP_IOU_THRESH,\n",
    "    box_format=\"midpoint\",\n",
    "    num_classes=config.NUM_CLASSES,\n",
    ")\n",
    "print(f\"MAP: {mapval.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70674f1d-5be4-4735-9bce-d96f9cbb75d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv2D19(\n",
       "  (backbone): DarkNet_19(\n",
       "    (conv_1): Sequential(\n",
       "      (0): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_2): Sequential(\n",
       "      (0): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_3): Sequential(\n",
       "      (0): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv_4): Sequential(\n",
       "      (0): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (maxpool_4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_5): Sequential(\n",
       "      (0): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (maxpool_5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_6): Sequential(\n",
       "      (0): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Conv_BN_LeakyReLU(\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (convsets_1): Sequential(\n",
       "    (0): Conv_BN_LeakyReLU(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv_BN_LeakyReLU(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (route_layer): Conv_BN_LeakyReLU(\n",
       "    (convs): Sequential(\n",
       "      (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (reorg): reorg_layer()\n",
       "  (convsets_2): Conv_BN_LeakyReLU(\n",
       "    (convs): Sequential(\n",
       "      (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pred): Conv2d(1024, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f5f1c-f7e1-44f5-9bc4-30fc5c772566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New Python (GPU)",
   "language": "python",
   "name": "new_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
