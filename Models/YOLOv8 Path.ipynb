{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b66103-b466-4697-867a-49e611fae097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d074d533-b3de-43f7-aeda-e373aba7a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Models.block import *\n",
    "from torch.autograd.profiler import record_function\n",
    "from torch.nn.modules.upsampling import Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8d12508-0bb2-426e-a24d-ce06fb4318bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337405e1-a59a-49a2-b6c9-4d0960c138a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, \n",
    "                 device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = out_channels//2\n",
    "        self.conv1 = Conv(in_channels, out_channels=self.hidden_channels, kernel_size=(1,1), stride=(1,1),\n",
    "                          padding=(0,0), bias=False,\n",
    "                          device=device, dtype=dtype)\n",
    "        self.conv2 = Conv(self.hidden_channels * 4, out_channels=out_channels, kernel_size=(1,1), stride=(1,1), \n",
    "                          padding=(0,0), bias=False,\n",
    "                          device=device, dtype=dtype)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=kernel_size, stride=(1,1), padding=kernel_size // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        \n",
    "        _l = [out]\n",
    "        for i in range(3):\n",
    "            out = self.max_pool(out)\n",
    "            _l.append(out)\n",
    "        out = torch.cat(_l, 1)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581424fe-3253-47e9-a86c-2c5f0ed50a9c",
   "metadata": {},
   "source": [
    "# Can I decrease the number of tensors created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0f73ee-ecaf-4b20-8daf-38f409ea271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, residual_connection=False, \n",
    "                 CSP=True, add_hidden=True, variant='n',\n",
    "                 device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if variant not in Model.variants.keys():\n",
    "            raise Exception(\"Invalid variant.\")\n",
    "            \n",
    "        self.variant = variant\n",
    "        self.mc = Model.variants[self.variant]['mc']\n",
    "        self.w = Model.variants[self.variant]['w']\n",
    "        self.d = Model.variants[self.variant]['d']\n",
    "        \n",
    "        self.upsample = Upsample(scale_factor=2.0, mode='nearest')\n",
    "\n",
    "        self.c2f_16 = C2f(self._ch(512)+self._ch(1024), out_channels=self._ch(512), n=self._d(3), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "\n",
    "        self.c2f_8 = C2f(self._ch(256)+self._ch(512), out_channels=self._ch(256), n=self._d(3), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "        \n",
    "        \n",
    "    def forward(self, out_8, out_16, out_32):\n",
    "        out = self.upsample(out_32)\n",
    "\n",
    "        out = torch.cat([out, out_16], 1)\n",
    "        out_16 = self.c2f_16(out)\n",
    "\n",
    "        out = self.upsample(out_16)\n",
    "        out = torch.cat([out, out_8], 1)\n",
    "        out = self.c2f_8(out)\n",
    "\n",
    "        return out, out_16, out_32\n",
    "\n",
    "    def _ch(self, ch):\n",
    "        return int(min(ch, self.mc)*self.w)\n",
    "\n",
    "    def _d(self, d):\n",
    "        return int(d * self.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7299ce30-be34-4399-bb67-eed142c95e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANet(nn.Module):\n",
    "    def __init__(self, residual_connection=False, \n",
    "                 CSP=True, add_hidden=True, variant='n',\n",
    "                 device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if variant not in Model.variants.keys():\n",
    "            raise Exception(\"Invalid variant.\")\n",
    "            \n",
    "        self.variant = variant\n",
    "        self.mc = Model.variants[self.variant]['mc']\n",
    "        self.w = Model.variants[self.variant]['w']\n",
    "        self.d = Model.variants[self.variant]['d']\n",
    "        \n",
    "        self.conv8_16 = Conv(self._ch(256), out_channels=self._ch(256), kernel_size=(3,3), stride=(2,2),\n",
    "                          padding=(1,1), bias=False,\n",
    "                          device=device, dtype=dtype)\n",
    "\n",
    "        self.c2f_16 = C2f(self._ch(256)+self._ch(512), out_channels=self._ch(512), n=self._d(3), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "\n",
    "        self.conv16_32 = Conv(self._ch(512), out_channels=self._ch(512), kernel_size=(3,3), stride=(2,2),\n",
    "                          padding=(1,1), bias=False,\n",
    "                          device=device, dtype=dtype)\n",
    "\n",
    "        self.c2f_32 = C2f(self._ch(1024)+self._ch(512), out_channels=self._ch(1024), n=self._d(3), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "\n",
    "    def _ch(self, ch):\n",
    "        return int(min(ch, self.mc)*self.w)\n",
    "\n",
    "    def _d(self, d):\n",
    "        return int(d * self.d)\n",
    "\n",
    "    def forward(self, out_8, out_16, out_32):\n",
    "        out = self.conv8_16(out_8)\n",
    "\n",
    "        out = torch.cat([out, out_16], 1)\n",
    "        out_16 = self.c2f_16(out)\n",
    "\n",
    "        out = self.conv16_32(out_16)\n",
    "        out = torch.cat([out, out_32], 1)\n",
    "        out = self.c2f_32(out)\n",
    "        \n",
    "        return out_8, out_16, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "618a7feb-e5d8-4698-8f24-4622a3285574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(nn.Module):\n",
    "    def __init__(self, in_channels, decoupled=True,\n",
    "                 num_classes=80, num_boxes=16, variant='n',\n",
    "                 device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.decoupled = decoupled\n",
    "        \n",
    "        if variant not in Model.variants.keys():\n",
    "            raise Exception(\"Invalid variant.\")\n",
    "        self.variant = variant\n",
    "        self.mc = Model.variants[self.variant]['mc']\n",
    "        self.w = Model.variants[self.variant]['w']\n",
    "        self.d = Model.variants[self.variant]['d']\n",
    "\n",
    "        ch_0 = int(self.w*256)\n",
    "        bbox_hidden, cls_hidden = max((16, ch_0 // 4, num_boxes * 4)), max(ch_0, min(num_classes, 100))\n",
    "\n",
    "        if decoupled:\n",
    "            self.bbox_conv1 = Conv(in_channels, out_channels=bbox_hidden, kernel_size=(3,3), stride=(1,1),\n",
    "                              padding=(1,1), bias=False,\n",
    "                              device=device, dtype=dtype)\n",
    "    \n",
    "            self.bbox_conv2 = Conv(bbox_hidden, out_channels=bbox_hidden, kernel_size=(3,3), stride=(1,1),\n",
    "                              padding=(1,1), bias=False,\n",
    "                              device=device, dtype=dtype)\n",
    "            \n",
    "            self.bbox_conv3 = nn.Conv2d(bbox_hidden, out_channels=num_boxes * 4, kernel_size=(1,1), stride=(1,1), \n",
    "                                        padding=(0,0), bias=True, \n",
    "                                        device=device, dtype=dtype)\n",
    "\n",
    "            self.cls_conv1 = Conv(in_channels, out_channels=cls_hidden, kernel_size=(3,3), stride=(1,1),\n",
    "                              padding=(1,1), bias=False,\n",
    "                              device=device, dtype=dtype)\n",
    "    \n",
    "            self.cls_conv2 = Conv(cls_hidden, out_channels=cls_hidden, kernel_size=(3,3), stride=(1,1),\n",
    "                              padding=(1,1), bias=False,\n",
    "                              device=device, dtype=dtype)\n",
    "\n",
    "            self.cls_conv3 = nn.Conv2d(cls_hidden, out_channels=num_classes, kernel_size=(1,1), stride=(1,1), \n",
    "                                        padding=(0,0), bias=True, \n",
    "                                        device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.decoupled:\n",
    "            out_bb = self.bbox_conv1(x)\n",
    "            out_bb = self.bbox_conv2(out_bb)\n",
    "            out_bb = self.bbox_conv3(out_bb)\n",
    "\n",
    "            out_cls = self.cls_conv1(x)\n",
    "            out_cls = self.cls_conv2(out_cls)\n",
    "            out_cls = self.cls_conv3(out_cls)\n",
    "\n",
    "            return out_bb, out_cls\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "92fc58b7-efee-42d8-8c40-9615c42611a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFL(nn.Module):\n",
    "    \"\"\"\n",
    "    Integral module of Distribution Focal Loss (DFL).\n",
    "\n",
    "    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c1=16):\n",
    "        \"\"\"Initialize a convolutional layer with a given number of input channels.\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n",
    "        x = torch.arange(c1, dtype=torch.float)\n",
    "        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n",
    "        self.c1 = c1\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies a transformer layer on input tensor 'x' and returns a tensor.\"\"\"\n",
    "        b, _, a = x.shape  # batch, channels, anchors\n",
    "        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)\n",
    "        # return self.conv(x.view(b, self.c1, 4, a).softmax(1)).view(b, 4, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5dd715df-ed8f-4caa-91e2-1783ee5f59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    variants = {'n': {'d': 0.34, 'w': 0.25, 'mc': 1024},\n",
    "                's': {'d': 0.34, 'w': 0.50, 'mc': 1024},\n",
    "                'm': {'d': 0.67, 'w': 0.75, 'mc': 768},\n",
    "                'l': {'d': 1.00, 'w': 1.00, 'mc': 512},\n",
    "                'x': {'d': 1.00, 'w': 1.25, 'mc': 512}}\n",
    "\n",
    "    def __init__(self, three_heads=True, decoupled=True,\n",
    "                 _FPN=True, _PANet=True, _SPPF=True, v8_loss=True,\n",
    "                 num_classes=80, num_boxes=16, variant='n', \n",
    "                 device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.three_heads = three_heads\n",
    "        self._FPN = _FPN\n",
    "        self._PANet = _PANet\n",
    "        self._SPPF = _SPPF\n",
    "        self.v8_loss = v8_loss\n",
    "\n",
    "        # Backbone model parameters\n",
    "        residual_connection = True\n",
    "        CSP = True\n",
    "        add_hidden = True\n",
    "        bottleneck = 1.0\n",
    "        \n",
    "        if variant not in Model.variants.keys():\n",
    "            raise Exception(\"Invalid variant.\")\n",
    "        self.variant = variant\n",
    "        self.mc = Model.variants[self.variant]['mc']\n",
    "        self.w = Model.variants[self.variant]['w']\n",
    "        self.d = Model.variants[self.variant]['d']\n",
    "        \n",
    "\n",
    "        self.conv1 = Conv(3, out_channels=self._ch(64), kernel_size=(3, 3), stride=(2, 2), \n",
    "                         padding=(1, 1), bias=False, \n",
    "                         device=device, dtype=dtype)\n",
    "        self.conv2 = Conv(self._ch(64), out_channels=self._ch(128), kernel_size=(3, 3), stride=(2, 2), \n",
    "                          padding=(1, 1), bias=False,\n",
    "                          device=device, dtype=dtype)\n",
    "        self.c2f1 = C2f(self._ch(128), out_channels=self._ch(128), n=self._d(3), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "        self.conv3 = Conv(self._ch(128), out_channels=self._ch(256), kernel_size=(3, 3), stride=(2, 2), \n",
    "                         padding=(1, 1), bias=False, \n",
    "                         device=device, dtype=dtype)\n",
    "        self.c2f2 = C2f(self._ch(256), out_channels=self._ch(256), n=self._d(6), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "        # c2f2 --- stride 8 ---->\n",
    "        \n",
    "        self.conv4 = Conv(self._ch(256), out_channels=self._ch(512), kernel_size=(3, 3), stride=(2, 2), \n",
    "                         padding=(1, 1), bias=False, \n",
    "                         device=device, dtype=dtype)\n",
    "        self.c2f3 = C2f(self._ch(512), out_channels=self._ch(512), n=self._d(6), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "        # c2f3 --- stride 16 ---->\n",
    "        \n",
    "        self.conv5 = Conv(self._ch(512), out_channels=self._ch(1024), kernel_size=(3, 3), stride=(2, 2), \n",
    "                         padding=(1, 1), bias=False, \n",
    "                         device=device, dtype=dtype)\n",
    "        self.c2f4 = C2f(self._ch(1024), out_channels=self._ch(1024), n=self._d(3), residual_connection=residual_connection, \n",
    "                        CSP=CSP, add_hidden=add_hidden, bottleneck=1.0,\n",
    "                        device=device, dtype=dtype)\n",
    "\n",
    "        if _SPPF:\n",
    "            self.sppf = SPPF(self._ch(1024), out_channels=self._ch(1024), kernel_size=5,\n",
    "                            device=device, dtype=dtype)\n",
    "        # sppf --- stride 32 ---->\n",
    "\n",
    "        if _FPN:\n",
    "            self.fpn = FPN(residual_connection=False, \n",
    "                           CSP=CSP, add_hidden=add_hidden, \n",
    "                           variant=variant,\n",
    "                           device=device, dtype=dtype)\n",
    "\n",
    "        if _PANet:\n",
    "            self.panet = PANet(residual_connection=False, \n",
    "                           CSP=CSP, add_hidden=add_hidden, \n",
    "                           variant=variant,\n",
    "                           device=device, dtype=dtype)\n",
    "\n",
    "        if three_heads:\n",
    "            self.detect_8 = Detect(self._ch(256), decoupled=decoupled,\n",
    "                                   num_classes=num_classes, num_boxes=num_boxes, \n",
    "                                   variant=variant, device=device, dtype=dtype)\n",
    "    \n",
    "            self.detect_16 = Detect(self._ch(512), decoupled=decoupled,\n",
    "                                   num_classes=num_classes, num_boxes=num_boxes, \n",
    "                                   variant=variant, device=device, dtype=dtype)\n",
    "    \n",
    "            self.detect_32 = Detect(self._ch(1024), decoupled=decoupled,\n",
    "                                   num_classes=num_classes, num_boxes=num_boxes, \n",
    "                                   variant=variant, device=device, dtype=dtype)\n",
    "            \n",
    "        if v8_loss:\n",
    "            self.dfl = DFL()\n",
    "\n",
    "    \n",
    "    def _ch(self, ch):\n",
    "        return int(min(ch, self.mc)*self.w)\n",
    "\n",
    "    def _d(self, d):\n",
    "        return int(d * self.d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with record_function('conv1'):\n",
    "            out = self.conv1(x)\n",
    "        \n",
    "        with record_function('conv2'):\n",
    "            out = self.conv2(out)\n",
    "        with record_function('c2f1'):\n",
    "            out = self.c2f1(out)\n",
    "\n",
    "        with record_function('conv3'):\n",
    "            out = self.conv3(out)\n",
    "        with record_function('c2f2'):\n",
    "            out = self.c2f2(out)\n",
    "        \n",
    "        # c2f2 --- stride 8 ---->\n",
    "        out_8 = out\n",
    "            \n",
    "        with record_function('conv4'):\n",
    "            out = self.conv4(out)\n",
    "        with record_function('c2f3'):\n",
    "            out = self.c2f3(out)\n",
    "\n",
    "        # c2f3 --- stride 16 ---->\n",
    "        out_16 = out\n",
    "            \n",
    "        with record_function('conv5'):\n",
    "            out = self.conv5(out)\n",
    "        with record_function('c2f4'):\n",
    "            out = self.c2f4(out)\n",
    "\n",
    "        if self._SPPF:\n",
    "            with record_function('sppf'):\n",
    "                out = self.sppf(out)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # sppf --- stride 32 ---->\n",
    "        if self._FPN:\n",
    "            with record_function('fpn'):\n",
    "                out_8, out_16, out = self.fpn(out_8, out_16, out)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        if self._PANet:\n",
    "            with record_function('panet'):\n",
    "                out_8, out_16, out = self.panet(out_8, out_16, out)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self.three_heads:\n",
    "            with record_function('detect'):\n",
    "                out_8 = self.detect_8(out_8)\n",
    "                out_16 = self.detect_16(out_16)\n",
    "                out = self.detect_32(out)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self.v8_loss:\n",
    "            self.dfl()\n",
    "            \n",
    "            \n",
    "        return out_8, out_16, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299821bf-004c-4722-9fba-95ada172129f",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/any-purpose-to-set-bias-false-in-densenet-torchvision/22067/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0d50a19e-0f0f-4aaf-a954-98111e329747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for variant in ['n', 's', 'm', 'l', 'x']:\n",
    "    model = Model(three_heads=True, decoupled=True,\n",
    "                     _FPN=True, _PANet=True, _SPPF=True, v8_loss=False,\n",
    "                     num_classes=80, num_boxes=16, variant=variant, \n",
    "                     device=None, dtype=None)\n",
    "    my_count = count_parameters(model)\n",
    "    model = YOLO(f\"yolov8{variant}.pt\").model.model\n",
    "    their_count = count_parameters(model)\n",
    "    print(their_count-my_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c5ad1ae9-78b4-46fc-add3-e06fd9e0da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(three_heads=True, decoupled=True,\n",
    "                     _FPN=True, _PANet=True, _SPPF=True, v8_loss=False,\n",
    "                     num_classes=80, num_boxes=16, variant='n', \n",
    "                     device=None, dtype=None)\n",
    "img = torch.rand(1,3,640,640)\n",
    "out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4f233f52-34d3-4190-b2a3-69ae91ff9e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5a2a8aeb-c1d1-4945-905c-77a159033b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75ea18-f6d4-4ef0-a105-c6a45292b93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
