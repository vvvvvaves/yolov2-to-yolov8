{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512e4cb2-1f99-40fb-ba8d-f0663195ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from yolov2 import YOLOv2D19 as YOLOv2\n",
    "from detection_datasets import VOCDatasetV2\n",
    "from torch import optim\n",
    "from loss import YOLOv2Loss\n",
    "from train import *\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from data_preprocessing import get_norms\n",
    "import pickle\n",
    "with open('anchors_VOC0712trainval.pickle', 'rb') as handle:\n",
    "    anchors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1532df2e-63db-4870-8e33-66a09981579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5be9e7-fd4d-484d-9feb-0d6007fda614",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = get_norms('../../datasets/VOCdevkit/trainval_norms.json')\n",
    "means = norms['means']\n",
    "stds = norms['stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4971daae-6ce2-4f48-80a5-1d294e02b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ../../datasets/VOCdevkit/VOC2007\\ImageSets\\Main\\trainval.txt\n",
      "True ../../datasets/VOCdevkit/VOC2012\\ImageSets\\Main\\trainval.txt\n",
      "True ../../datasets/VOCdevkit/VOC2007\\ImageSets\\Main\\test.txt\n"
     ]
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(width=416, height=416),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    # A.Normalize(mean=means, std=stds),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "train_set = VOCDatasetV2(devkit_path = '../../datasets/VOCdevkit/', scales=[13], anchors=anchors, transforms=transforms, \n",
    "                         dtype=torch.float32, device=torch.device('cuda:0'))\n",
    "val_set = VOCDatasetV2(devkit_path = '../../datasets/VOCdevkit/', \n",
    "                       subsets = [('VOC2007', 'test')],\n",
    "                       scales=[13], anchors=anchors, transforms=transforms, \n",
    "                       dtype=torch.float32, device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6678c8fe-8e98-47d8-9ec0-879cc36a4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8350ff7-f3c8-42cb-bcd7-6f735a8d12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YOLOv2Loss(anchors=anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066fb3de-2511-4b39-bedd-9ca3241ddeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\yolov2.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "model = YOLOv2(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f700978-3cb3-478b-91a0-e910995633ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6002a881-de16-4ba7-8c62-d3b828b36f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b716bbab-6826-4f8c-b7eb-03c1597555d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 10:29:14.818788 Epoch 1 \n",
      "2024-12-22 10:29:15.464221 After batch load / before to(cuda)\n",
      "2024-12-22 10:29:15.464221 After to(cuda)\n",
      "2024-12-22 10:29:15.464221 Batch 1 \n",
      "2024-12-22 10:29:15.464221 Before inference on 64 batch\n",
      "2024-12-22 10:29:31.394065 After inference on 64 batch / before loss fn\n",
      "2024-12-22 10:29:39.074182 After loss fn / before zero grad\n",
      "2024-12-22 10:29:39.074182 After zero grad / before backward\n",
      "2024-12-22 10:30:28.028630 After backward / before optimizer.step\n",
      "2024-12-22 10:30:28.055681 After optimizer.step / before += loss.item()\n",
      "2024-12-22 10:30:28.196609 After += loss.item() / before the next batch\n",
      "2024-12-22 10:30:28.895733 After batch load / before to(cuda)\n",
      "2024-12-22 10:30:28.895733 After to(cuda)\n",
      "2024-12-22 10:30:28.895733 Batch 2 \n",
      "2024-12-22 10:30:28.895733 Before inference on 64 batch\n",
      "2024-12-22 10:30:29.183639 After inference on 64 batch / before loss fn\n",
      "2024-12-22 10:30:49.256513 After loss fn / before zero grad\n",
      "2024-12-22 10:30:49.257558 After zero grad / before backward\n",
      "2024-12-22 10:30:49.278400 After backward / before optimizer.step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history, gradient_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../log/YOLOv2/training/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\..\\train.py:39\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path, save_at, save_grad, resume)\u001b[0m\n\u001b[0;32m     37\u001b[0m _datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_datetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m train_map, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m val_map, val_loss \u001b[38;5;241m=\u001b[39m validation_loop(model, val_loader, loss_fn)\n\u001b[0;32m     42\u001b[0m _gradient_stats \u001b[38;5;241m=\u001b[39m get_gradient_stats(model)\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\..\\loop.py:42\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[0;32m     39\u001b[0m _datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_datetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m After backward / before optimizer.step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m _datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_datetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m After optimizer.step / before += loss.item()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\optim\\sgd.py:123\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m momentum_buffer_list: List[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    119\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    120\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[0;32m    121\u001b[0m )\n\u001b[1;32m--> 123\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\optim\\sgd.py:298\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[1;32m--> 298\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\optim\\sgd.py:414\u001b[0m, in \u001b[0;36m_multi_tensor_sgd\u001b[1;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    411\u001b[0m         bufs\u001b[38;5;241m.\u001b[39mappend(cast(Tensor, device_momentum_buffer_list[i]))\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_states_with_momentum_buffer:\n\u001b[1;32m--> 414\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(bufs, device_grads, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dampening)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../log/YOLOv2/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "300f5052-7022-4eaa-b0d4-18dd1a7f65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, out, gt_out):\n",
    "        return self.mse(out, gt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "524ff80a-aded-4d21-a91a-29ff9b2c90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv2Loss(nn.Module):\n",
    "    def __init__(self, anchors, lambda_noobj=0.5, lambda_coord=5.0, num_classes=20):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss(reduction='sum')\n",
    "        self.softmax = torch.nn.Softmax(dim=2)\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        \n",
    "    def forward(self, out, gt_out):\n",
    "        \n",
    "        # [conf, obj_xc, obj_yc, obj_w, obj_h]\n",
    "        is_obj = gt_out[:, 0::25, ...] == 1.0\n",
    "        no_obj = gt_out[:, 0::25, ...] == 0.0\n",
    "\n",
    "        # CONFIDENCE LOSS ===========\n",
    "        conf_true = gt_out[:, 0::25, ...]\n",
    "        conf_pred = out[:, 0::25, ...].sigmoid()\n",
    "\n",
    "        is_obj_conf_pred = is_obj * conf_pred\n",
    "        is_obj_conf_true = is_obj * conf_true\n",
    "        \n",
    "        no_obj_conf_pred = no_obj * conf_pred\n",
    "        no_obj_conf_true = no_obj * conf_true\n",
    "\n",
    "        is_obj_conf_loss = self.mse(is_obj_conf_pred, is_obj_conf_true)\n",
    "        no_obj_conf_loss = self.mse(no_obj_conf_pred, no_obj_conf_true) \n",
    "        # ===========================\n",
    "\n",
    "        # BOX LOSS ==================\n",
    "        xc_true = gt_out[:, 1::25, ...]\n",
    "        yc_true = gt_out[:, 2::25, ...]\n",
    "        w_true = gt_out[:, 3::25, ...]\n",
    "        h_true = gt_out[:, 4::25, ...]\n",
    "        \n",
    "        xc_pred = out[:, 1::25, ...].sigmoid()\n",
    "        yc_pred = out[:, 2::25, ...].sigmoid()\n",
    "        \n",
    "        scale = gt_out.shape[-1]\n",
    "        _anchors = torch.tensor(self.anchors).to(out.device) * scale\n",
    "        pw = _anchors[:, 0]\n",
    "        ph = _anchors[:, 1]\n",
    "        \n",
    "        w_pred = pw[None, :, None, None] * out[:, 3::25, ...].exp()\n",
    "        h_pred = ph[None, :, None, None] * out[:, 4::25, ...].exp()\n",
    "\n",
    "        xc_pred = is_obj * xc_pred\n",
    "        xc_true = is_obj * xc_true\n",
    "        yc_pred = is_obj * yc_pred\n",
    "        yc_true = is_obj * yc_true\n",
    "        \n",
    "        w_pred = is_obj * w_pred\n",
    "        w_true = is_obj * w_true\n",
    "        h_pred = is_obj * h_pred\n",
    "        h_true = is_obj * h_true\n",
    "\n",
    "        xc_loss = self.mse(xc_pred, xc_true)\n",
    "        yc_loss = self.mse(yc_pred, yc_true)\n",
    "        w_loss = self.mse(w_pred.sqrt(), w_true.sqrt())\n",
    "        h_loss = self.mse(h_pred.sqrt(), h_true.sqrt())\n",
    "        # ===========================\n",
    "\n",
    "        # CLASS LOSS ================\n",
    "        class_true = []\n",
    "        for i in range(len(self.anchors)):\n",
    "            first_idx = 5 + i*(5+self.num_classes)\n",
    "            last_idx = 25 + i*(5+self.num_classes)\n",
    "            class_true.append(gt_out[:, first_idx:last_idx, ...])\n",
    "        class_true = torch.stack(class_true, dim=1)\n",
    "\n",
    "        class_pred = []\n",
    "        for i in range(len(self.anchors)):\n",
    "            first_idx = 5 + i*(5+self.num_classes)\n",
    "            last_idx = 25 + i*(5+self.num_classes)\n",
    "            class_pred.append(gt_out[:, first_idx:last_idx, ...])\n",
    "        class_pred = torch.stack(class_pred, dim=1)\n",
    "\n",
    "        class_pred = self.softmax(class_pred)\n",
    "        \n",
    "        class_pred = is_obj[:, :, None, :, :] * class_pred\n",
    "        class_true = is_obj[:, :, None, :, :] * class_true\n",
    "\n",
    "        class_loss = self.mse(class_pred, class_true)\n",
    "        # ===========================\n",
    "\n",
    "        loss =  self.lambda_coord * (xc_loss + yc_loss) + \\\n",
    "                self.lambda_coord * (w_loss + h_loss) + \\\n",
    "                is_obj_conf_loss + \\\n",
    "                self.lambda_noobj * no_obj_conf_loss + \\\n",
    "                class_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d972651d-b05f-4ffa-83df-e093e083adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_set[0]\n",
    "label = label.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36867424-95a6-4c6d-b179-73fdbf0556cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef767a22-695e-43d2-8a6c-f19f00a2b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YOLOv2Loss(anchors=anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "838d7869-c520-49e0-b6ec-87169a65b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a3dd78e-3a7b-451a-aa78-78afdcba5073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 10:49:31.458892 Before\n",
      "2024-12-22 10:49:31.468289 After\n"
     ]
    }
   ],
   "source": [
    "_datetime = datetime.datetime.now()\n",
    "print(f\"{_datetime} Before\")\n",
    "loss.backward()\n",
    "_datetime = datetime.datetime.now()\n",
    "print(f\"{_datetime} After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6af6f52-9026-4334-96ef-6b38c168d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb8dd43f-8a02-41ff-a81d-4892873a0205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv2Loss(\n",
       "  (mse): MSELoss()\n",
       "  (softmax): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7bdcc5d2-c2c9-4a5e-a61d-04d6586b9c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 50.,  64.,  82.,  ...,  61.,  67.,  69.],\n",
       "         [ 39.,  40.,  53.,  ...,  63.,  68.,  69.],\n",
       "         [ 33.,  32.,  30.,  ...,  58.,  61.,  61.],\n",
       "         ...,\n",
       "         [ 33.,  19.,  12.,  ..., 162., 162., 162.],\n",
       "         [  5.,   9.,  10.,  ..., 161., 161., 161.],\n",
       "         [ 11.,  12.,  10.,  ..., 164., 163., 162.]],\n",
       "\n",
       "        [[ 17.,  22.,  29.,  ...,  76.,  82.,  84.],\n",
       "         [  8.,   9.,  18.,  ...,  77.,  83.,  84.],\n",
       "         [ 11.,  13.,  11.,  ...,  72.,  74.,  74.],\n",
       "         ...,\n",
       "         [ 36.,  20.,  12.,  ..., 189., 189., 189.],\n",
       "         [  5.,   9.,  10.,  ..., 187., 188., 187.],\n",
       "         [  9.,  12.,  11.,  ..., 187., 186., 185.]],\n",
       "\n",
       "        [[  5.,  13.,  16.,  ..., 105., 111., 113.],\n",
       "         [  2.,   3.,   6.,  ..., 106., 111., 113.],\n",
       "         [  7.,  11.,   3.,  ..., 103., 106., 105.],\n",
       "         ...,\n",
       "         [ 39.,  22.,  14.,  ..., 198., 198., 198.],\n",
       "         [  7.,   9.,  10.,  ..., 194., 194., 194.],\n",
       "         [ 10.,  12.,  11.,  ..., 193., 192., 191.]]], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e024b-6a69-4adf-89d9-4567160b2ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New Python (GPU)",
   "language": "python",
   "name": "new_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
