{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512e4cb2-1f99-40fb-ba8d-f0663195ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from yolov2 import YOLOv2D19 as YOLOv2\n",
    "from detection_datasets import VOCDatasetV2\n",
    "from torch import optim\n",
    "from loss import YOLOv2Loss\n",
    "from train import *\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from data_preprocessing import get_norms\n",
    "import pickle\n",
    "with open('anchors_VOC0712trainval.pickle', 'rb') as handle:\n",
    "    anchors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1532df2e-63db-4870-8e33-66a09981579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "dtype=torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5be9e7-fd4d-484d-9feb-0d6007fda614",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = get_norms('../../datasets/VOCdevkit/trainval_norms.json')\n",
    "means = norms['means']\n",
    "stds = norms['stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb80c18f-6c05-4344-9d04-c7b347020414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 MB\n",
      "Allocated memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "import gc\n",
    "\n",
    "# Invoke garbage collector\n",
    "gc.collect()\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4971daae-6ce2-4f48-80a5-1d294e02b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ../../datasets/VOCdevkit/VOC2012\\ImageSets\\Main\\trainval.txt\n",
      "True ../../datasets/VOCdevkit/VOC2007\\ImageSets\\Main\\val.txt\n"
     ]
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(width=416, height=416),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.Normalize(mean=means, std=stds),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "train_set = VOCDatasetV2(devkit_path = '../../datasets/VOCdevkit/', \n",
    "                         subsets = [('VOC2012', 'trainval')],\n",
    "                         scales=[13], anchors=anchors, transforms=transforms, \n",
    "                         dtype=dtype, device=device)\n",
    "val_set = VOCDatasetV2(devkit_path = '../../datasets/VOCdevkit/', \n",
    "                       subsets = [('VOC2007', 'val')],\n",
    "                       scales=[13], anchors=anchors, transforms=transforms, \n",
    "                       dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6678c8fe-8e98-47d8-9ec0-879cc36a4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8350ff7-f3c8-42cb-bcd7-6f735a8d12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YOLOv2Loss(anchors=anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066fb3de-2511-4b39-bedd-9ca3241ddeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\yolov2.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "model = YOLOv2(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f700978-3cb3-478b-91a0-e910995633ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6002a881-de16-4ba7-8c62-d3b828b36f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78dbf2-6d1d-4387-a7ad-141364343c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 21:09:36.418164 Epoch 1 \n",
      "2024-12-22 21:09:38.707747 Batch 1 \n",
      "Before inference 2024-12-22 21:09:38.748585\n",
      "After inference 2024-12-22 21:10:06.838459\n",
      "Loss start 2024-12-22 21:10:06.845463\n",
      "Conf start 2024-12-22 21:10:06.845463\n",
      "Box start 2024-12-22 21:10:06.925161\n",
      "Class start 2024-12-22 21:10:06.965458\n",
      "Sum everything 2024-12-22 21:10:07.026506\n",
      "After loss fn 2024-12-22 21:10:07.035632\n",
      "After scaler-loss backward 2024-12-22 21:11:07.895611\n",
      "After unscaling 2024-12-22 21:11:08.035497\n",
      "After scaler step 2024-12-22 21:11:08.038633\n",
      "After scaler update 2024-12-22 21:11:08.046458\n",
      "2024-12-22 21:11:09.942235 Batch 2 \n",
      "Before inference 2024-12-22 21:11:10.215371\n"
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../log/YOLOv2/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6930d60a-0bdd-4879-93b2-ee938083f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 20:45:13.981076 Epoch 1 \n",
      "2024-12-22 20:45:14.996489 Batch 1 \n",
      "Before inference 2024-12-22 20:45:15.015560\n",
      "After inference 2024-12-22 20:45:15.566507\n",
      "Loss start 2024-12-22 20:45:15.567513\n",
      "Conf start 2024-12-22 20:45:15.567513\n",
      "After loss fn 2024-12-22 20:45:15.606631\n",
      "After scaler-loss backward 2024-12-22 20:45:18.043209\n",
      "After unscaling 2024-12-22 20:45:18.059567\n",
      "After scaler step 2024-12-22 20:45:18.059567\n",
      "After scaler update 2024-12-22 20:45:18.059567\n",
      "2024-12-22 20:45:18.697031 Batch 2 \n",
      "Before inference 2024-12-22 20:45:18.697031\n",
      "After inference 2024-12-22 20:45:18.856477\n",
      "Loss start 2024-12-22 20:45:18.856477\n",
      "Conf start 2024-12-22 20:45:18.856477\n",
      "After loss fn 2024-12-22 20:45:18.856477\n",
      "After scaler-loss backward 2024-12-22 20:45:21.095372\n",
      "After unscaling 2024-12-22 20:45:21.095372\n",
      "After scaler step 2024-12-22 20:45:21.095372\n",
      "After scaler update 2024-12-22 20:45:21.095372\n",
      "2024-12-22 20:45:21.743539 Batch 3 \n",
      "Before inference 2024-12-22 20:45:21.744565\n",
      "After inference 2024-12-22 20:45:21.907107\n",
      "Loss start 2024-12-22 20:45:21.907199\n",
      "Conf start 2024-12-22 20:45:21.907199\n",
      "After loss fn 2024-12-22 20:45:21.908201\n",
      "After scaler-loss backward 2024-12-22 20:45:24.159566\n",
      "After unscaling 2024-12-22 20:45:24.164571\n",
      "After scaler step 2024-12-22 20:45:24.164571\n",
      "After scaler update 2024-12-22 20:45:24.164571\n",
      "2024-12-22 20:45:24.796898 Batch 4 \n",
      "Before inference 2024-12-22 20:45:24.796898\n",
      "After inference 2024-12-22 20:45:24.964656\n",
      "Loss start 2024-12-22 20:45:24.964656\n",
      "Conf start 2024-12-22 20:45:24.965179\n",
      "After loss fn 2024-12-22 20:45:24.965179\n",
      "After scaler-loss backward 2024-12-22 20:45:27.185298\n",
      "After unscaling 2024-12-22 20:45:27.185298\n",
      "After scaler step 2024-12-22 20:45:27.185298\n",
      "After scaler update 2024-12-22 20:45:27.185298\n",
      "2024-12-22 20:45:28.041666 Batch 5 \n",
      "Before inference 2024-12-22 20:45:28.042668\n",
      "After inference 2024-12-22 20:45:28.204431\n",
      "Loss start 2024-12-22 20:45:28.204431\n",
      "Conf start 2024-12-22 20:45:28.205456\n",
      "After loss fn 2024-12-22 20:45:28.205456\n",
      "After scaler-loss backward 2024-12-22 20:45:30.538555\n",
      "After unscaling 2024-12-22 20:45:30.540529\n",
      "After scaler step 2024-12-22 20:45:30.540529\n",
      "After scaler update 2024-12-22 20:45:30.540529\n",
      "2024-12-22 20:45:31.381410 Batch 6 \n",
      "Before inference 2024-12-22 20:45:31.381509\n",
      "After inference 2024-12-22 20:45:31.544404\n",
      "Loss start 2024-12-22 20:45:31.544404\n",
      "Conf start 2024-12-22 20:45:31.544404\n",
      "After loss fn 2024-12-22 20:45:31.545417\n",
      "After scaler-loss backward 2024-12-22 20:45:33.799433\n",
      "After unscaling 2024-12-22 20:45:33.799433\n",
      "After scaler step 2024-12-22 20:45:33.799433\n",
      "After scaler update 2024-12-22 20:45:33.799433\n",
      "2024-12-22 20:45:34.405443 Batch 7 \n",
      "Before inference 2024-12-22 20:45:34.405443\n",
      "After inference 2024-12-22 20:45:34.569865\n",
      "Loss start 2024-12-22 20:45:34.569865\n",
      "Conf start 2024-12-22 20:45:34.569865\n",
      "After loss fn 2024-12-22 20:45:34.569865\n",
      "After scaler-loss backward 2024-12-22 20:45:36.799705\n",
      "After unscaling 2024-12-22 20:45:36.806388\n",
      "After scaler step 2024-12-22 20:45:36.806388\n",
      "After scaler update 2024-12-22 20:45:36.806388\n",
      "2024-12-22 20:45:37.489113 Batch 8 \n",
      "Before inference 2024-12-22 20:45:37.492617\n",
      "After inference 2024-12-22 20:45:37.649834\n",
      "Loss start 2024-12-22 20:45:37.654338\n",
      "Conf start 2024-12-22 20:45:37.654338\n",
      "After loss fn 2024-12-22 20:45:37.655358\n",
      "After scaler-loss backward 2024-12-22 20:45:39.894363\n",
      "After unscaling 2024-12-22 20:45:39.896447\n",
      "After scaler step 2024-12-22 20:45:39.896447\n",
      "After scaler update 2024-12-22 20:45:39.896447\n",
      "2024-12-22 20:45:40.590165 Batch 9 \n",
      "Before inference 2024-12-22 20:45:40.590165\n",
      "After inference 2024-12-22 20:45:40.756702\n",
      "Loss start 2024-12-22 20:45:40.756702\n",
      "Conf start 2024-12-22 20:45:40.756702\n",
      "After loss fn 2024-12-22 20:45:40.756702\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history, gradient_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../log/YOLOv2/training/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\..\\train.py:41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path, save_at, save_grad, resume, scaler)\u001b[0m\n\u001b[0;32m     39\u001b[0m _datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_datetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m train_map, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m val_map, val_loss \u001b[38;5;241m=\u001b[39m validation_loop(model, val_loader, loss_fn)\n\u001b[0;32m     44\u001b[0m _gradient_stats \u001b[38;5;241m=\u001b[39m get_gradient_stats(model)\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\..\\loop.py:30\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(optimizer, model, loss_fn, train_loader, scaler)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter loss fn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 30\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter scaler-loss backward \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\cuda\\__init__.py:954\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    952\u001b[0m _lazy_init()\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../log/YOLOv2/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b716bbab-6826-4f8c-b7eb-03c1597555d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 20:43:35.379370 Epoch 1 \n",
      "2024-12-22 20:43:36.406915 Batch 1 \n",
      "Before inference 2024-12-22 20:43:36.425448\n",
      "After inference 2024-12-22 20:43:36.980048\n",
      "Loss start 2024-12-22 20:43:36.980048\n",
      "Conf start 2024-12-22 20:43:36.980048\n",
      "Box start 2024-12-22 20:43:37.018984\n",
      "Class start 2024-12-22 20:43:37.043258\n",
      "Sum everything 2024-12-22 20:43:37.067808\n",
      "After loss fn 2024-12-22 20:43:37.074276\n",
      "After scaler-loss backward 2024-12-22 20:43:39.867387\n",
      "After unscaling 2024-12-22 20:43:39.887851\n",
      "After scaler step 2024-12-22 20:43:39.887851\n",
      "After scaler update 2024-12-22 20:43:39.888851\n",
      "2024-12-22 20:43:40.670400 Batch 2 \n",
      "Before inference 2024-12-22 20:43:40.670400\n",
      "After inference 2024-12-22 20:43:40.833210\n",
      "Loss start 2024-12-22 20:43:40.833210\n",
      "Conf start 2024-12-22 20:43:40.833210\n",
      "Box start 2024-12-22 20:43:40.833210\n",
      "Class start 2024-12-22 20:43:40.834715\n",
      "Sum everything 2024-12-22 20:43:40.835227\n",
      "After loss fn 2024-12-22 20:43:40.835227\n",
      "After scaler-loss backward 2024-12-22 20:43:43.345190\n",
      "After unscaling 2024-12-22 20:43:43.345190\n",
      "After scaler step 2024-12-22 20:43:43.345190\n",
      "After scaler update 2024-12-22 20:43:43.345190\n",
      "2024-12-22 20:43:43.976826 Batch 3 \n",
      "Before inference 2024-12-22 20:43:43.976826\n",
      "After inference 2024-12-22 20:43:44.139893\n",
      "Loss start 2024-12-22 20:43:44.139893\n",
      "Conf start 2024-12-22 20:43:44.139893\n",
      "Box start 2024-12-22 20:43:44.139893\n",
      "Class start 2024-12-22 20:43:44.144407\n",
      "Sum everything 2024-12-22 20:43:44.145446\n",
      "After loss fn 2024-12-22 20:43:44.145446\n",
      "After scaler-loss backward 2024-12-22 20:43:46.694487\n",
      "After unscaling 2024-12-22 20:43:46.696867\n",
      "After scaler step 2024-12-22 20:43:46.696867\n",
      "After scaler update 2024-12-22 20:43:46.696867\n",
      "2024-12-22 20:43:47.347593 Batch 4 \n",
      "Before inference 2024-12-22 20:43:47.347593\n",
      "After inference 2024-12-22 20:43:47.506795\n",
      "Loss start 2024-12-22 20:43:47.506795\n",
      "Conf start 2024-12-22 20:43:47.506795\n",
      "Box start 2024-12-22 20:43:47.506795\n",
      "Class start 2024-12-22 20:43:47.514813\n",
      "Sum everything 2024-12-22 20:43:47.514813\n",
      "After loss fn 2024-12-22 20:43:47.515400\n",
      "After scaler-loss backward 2024-12-22 20:43:50.059630\n",
      "After unscaling 2024-12-22 20:43:50.066466\n",
      "After scaler step 2024-12-22 20:43:50.066466\n",
      "After scaler update 2024-12-22 20:43:50.066466\n",
      "2024-12-22 20:43:50.795567 Batch 5 \n",
      "Before inference 2024-12-22 20:43:50.795567\n",
      "After inference 2024-12-22 20:43:50.964528\n",
      "Loss start 2024-12-22 20:43:50.964528\n",
      "Conf start 2024-12-22 20:43:50.964528\n",
      "Box start 2024-12-22 20:43:50.965546\n",
      "Class start 2024-12-22 20:43:50.966794\n",
      "Sum everything 2024-12-22 20:43:50.966794\n",
      "After loss fn 2024-12-22 20:43:50.966794\n",
      "After scaler-loss backward 2024-12-22 20:43:53.423136\n",
      "After unscaling 2024-12-22 20:43:53.425154\n",
      "After scaler step 2024-12-22 20:43:53.425154\n",
      "After scaler update 2024-12-22 20:43:53.425154\n",
      "2024-12-22 20:43:54.194212 Batch 6 \n",
      "Before inference 2024-12-22 20:43:54.195056\n",
      "After inference 2024-12-22 20:43:54.356463\n",
      "Loss start 2024-12-22 20:43:54.356463\n",
      "Conf start 2024-12-22 20:43:54.356463\n",
      "Box start 2024-12-22 20:43:54.356463\n",
      "Class start 2024-12-22 20:43:54.356463\n",
      "Sum everything 2024-12-22 20:43:54.356463\n",
      "After loss fn 2024-12-22 20:43:54.356463\n",
      "After scaler-loss backward 2024-12-22 20:43:56.999393\n",
      "After unscaling 2024-12-22 20:43:56.999393\n",
      "After scaler step 2024-12-22 20:43:56.999393\n",
      "After scaler update 2024-12-22 20:43:56.999393\n",
      "2024-12-22 20:43:57.615211 Batch 7 \n",
      "Before inference 2024-12-22 20:43:57.615211\n",
      "After inference 2024-12-22 20:43:57.776701\n",
      "Loss start 2024-12-22 20:43:57.776701\n",
      "Conf start 2024-12-22 20:43:57.776701\n",
      "Box start 2024-12-22 20:43:57.776701\n",
      "Class start 2024-12-22 20:43:57.776701\n",
      "Sum everything 2024-12-22 20:43:57.776701\n",
      "After loss fn 2024-12-22 20:43:57.776701\n",
      "After scaler-loss backward 2024-12-22 20:44:00.396951\n",
      "After unscaling 2024-12-22 20:44:00.399107\n",
      "After scaler step 2024-12-22 20:44:00.400147\n",
      "After scaler update 2024-12-22 20:44:00.400147\n",
      "2024-12-22 20:44:01.125465 Batch 8 \n",
      "Before inference 2024-12-22 20:44:01.125465\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history, gradient_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../log/YOLOv2/training/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\..\\train.py:41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path, save_at, save_grad, resume, scaler)\u001b[0m\n\u001b[0;32m     39\u001b[0m _datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_datetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m train_map, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m val_map, val_loss \u001b[38;5;241m=\u001b[39m validation_loop(model, val_loader, loss_fn)\n\u001b[0;32m     44\u001b[0m _gradient_stats \u001b[38;5;241m=\u001b[39m get_gradient_stats(model)\n",
      "File \u001b[1;32mC:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Models\\..\\loop.py:23\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(optimizer, model, loss_fn, train_loader, scaler)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore inference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter inference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, labels)\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\cuda\\__init__.py:954\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    952\u001b[0m _lazy_init()\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../log/YOLOv2/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165fa073-8035-4c00-b270-58317920842b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New Python (GPU)",
   "language": "python",
   "name": "new_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
