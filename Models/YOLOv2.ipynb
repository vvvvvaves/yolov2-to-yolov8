{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c049b8c1-dcc6-4948-b9df-356c778e7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b1a5950-5470-4fe4-ad9d-12ba35b340e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from yolov2 import YOLOv2D19\n",
    "from iou import intersection_over_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a1909f-c58a-48b1-a30f-9c0e9691aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 125, 13, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLOv2D19()\n",
    "img = torch.rand(1,3,416,416).to(torch.device('cuda:0'))\n",
    "out = model(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0b40f103-bed9-4242-b1c0-f286966bed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S=13, B=5, C=20):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"mean\")\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, (self.C+5)*self.B)\n",
    "        batch_size = predictions.shape[0]\n",
    "        print(predictions.shape)\n",
    "\n",
    "        # x,y,w,h,c,classes\n",
    "        \n",
    "        ious = torch.zeros(batch_size, self.B, self.S, self.S, 1)\n",
    "        for b in range(self.B):\n",
    "            offset = b*25\n",
    "            pbox_idx = slice(0+offset,4+offset)\n",
    "            tbox_idx = slice(0,4)\n",
    "            \n",
    "            iou = intersection_over_union(\n",
    "                predictions[..., pbox_idx], \n",
    "                target[..., tbox_idx]\n",
    "            )\n",
    "\n",
    "            iou = torch.ones(2, 13, 13, 1).unsqueeze(1)\n",
    "            ious[:, b:b+1, ...] = iou\n",
    "\n",
    "        _, best_box = torch.max(ious, dim=0)\n",
    "        exists_box = target[..., 4:5]\n",
    "\n",
    "        # coord loss\n",
    "\n",
    "        best_box_offset = best_box*25\n",
    "        best_box_idx = slice(0+best_box_offset, 4+best_box_offset)\n",
    "        box_predictions = exists_box * predictions[..., best_box_idx]\n",
    "\n",
    "        return best_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bcb7d31c-ddd0-4914-b100-cb06dc81aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(out):\n",
    "    loss = YoloLoss()\n",
    "    predictions = torch.tensor([[[[7.5, 7.5, 10., 10., \n",
    "                       1., \n",
    "                       1., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                       0., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                      ]*5]*13]*13]*2)\n",
    "    target = torch.tensor([[[[7.5, 7.5, 10., 10., \n",
    "                       1., \n",
    "                       1., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                       0., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                      ]*1]*13]*13]*2)\n",
    "    return loss(predictions, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1263007b-7b04-4a25-85e2-8aea54783fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 13, 125])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[176], line 13\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(out)\u001b[0m\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[[\u001b[38;5;241m7.5\u001b[39m, \u001b[38;5;241m7.5\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \n\u001b[0;32m      4\u001b[0m                    \u001b[38;5;241m1.\u001b[39m, \n\u001b[0;32m      5\u001b[0m                    \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m      6\u001b[0m                    \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m      7\u001b[0m                   ]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[[\u001b[38;5;241m7.5\u001b[39m, \u001b[38;5;241m7.5\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \n\u001b[0;32m      9\u001b[0m                    \u001b[38;5;241m1.\u001b[39m, \n\u001b[0;32m     10\u001b[0m                    \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     11\u001b[0m                    \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     12\u001b[0m                   ]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Vstanovlene\\Anaconda Distribution\\envs\\new_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[175], line 40\u001b[0m, in \u001b[0;36mYoloLoss.forward\u001b[1;34m(self, predictions, target)\u001b[0m\n\u001b[0;32m     38\u001b[0m best_box_offset \u001b[38;5;241m=\u001b[39m best_box\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m     39\u001b[0m best_box_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m\u001b[38;5;241m+\u001b[39mbest_box_offset, \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m+\u001b[39mbest_box_offset)\n\u001b[1;32m---> 40\u001b[0m box_predictions \u001b[38;5;241m=\u001b[39m exists_box \u001b[38;5;241m*\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_box_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_box\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "test(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9de5685-4779-479c-8116-24cb47b6928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.tensor([[[[7.5, 7.5, 10., 10., \n",
    "                       1., \n",
    "                       1., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                       0., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                      ]*5]*13]*13]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "73b4599c-b5b1-4cdd-965c-5a1770cd78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = torch.zeros(2, 5, 13, 13, 1)\n",
    "_, best_box = torch.max(ious, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "73f3c471-31e2-4f4c-9767-bffe87f2ee26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 13, 1])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_box.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a732f-cc54-430a-a835-e2b2b794bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "30 = 20 cls, 4 coord, 1 conf, 4 coord, 1 conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
