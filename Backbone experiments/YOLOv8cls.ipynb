{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5258e5c-2fd1-45d6-bf25-96674d504f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9deb7c5-1256-4fdd-b447-69f25786c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b63379-9363-448e-b927-2231dbb097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from data_preprocessing import *\n",
    "from Models.yolov8cls_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdae16b-4251-46a6-865b-bfa81a9a5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3c5dd0-ac5d-4cbb-8463-d9ebe0621f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dummy_datasets/'\n",
    "norms_path = os.path.join(data_path, 'norms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e608e517-6da7-41c7-b62d-81cca6aecf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means are: [0.4405549168586731, 0.4407285749912262, 0.4381718039512634]\n",
      "stds are: [0.25142669677734375, 0.25270089507102966, 0.25131651759147644]\n"
     ]
    }
   ],
   "source": [
    "means = get_means(path=norms_path, train_loader=None)\n",
    "stds = get_stds(path=norms_path, train_loader=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840c3bfd-3f57-4508-9834-fd0c87b7532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Resize((224, 224)),\n",
    "                                      transforms.Normalize(mean=means, std=stds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfaadddf-3f19-4b50-93b4-98cf177980fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageNetSubset(path=data_path, train=True, transform=transformations, half=False, show=False)\n",
    "val_dataset = ImageNetSubset(path=data_path, train=False, transform=transformations, half=False, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e51cb9-eb5e-4869-9d89-db1aa508b589",
   "metadata": {},
   "source": [
    "YOLOv8n</br>\n",
    "Mine: 3.290265 GFLOPs ; On the website: 4.3 GFLOPs</br>\n",
    "YOLOv8s</br>\n",
    "Mine: 12.449996 GFLOPs ; On the website: 13.5 GFLOPs</br>\n",
    "YOLOv8m</br>\n",
    "Mine: 41.640755 GFLOPs ; On the website: 42.7 GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "352e4593-7d14-4b72-8cdd-3d5225ed5516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes=1000, \n",
    "              residual_connection=True, \n",
    "              CSP=True, \n",
    "              add_hidden=True,\n",
    "              classifyV8=True,\n",
    "              bottleneck=1.0, \n",
    "              variant='s', \n",
    "              device=device, \n",
    "              dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29fc3388-72b7-4eb7-9cac-f681ba4571bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,3,640,640)\n",
    "_ = transforms.Compose([transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])])\n",
    "img = _(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ffe079-6960-46d0-af78-9d7fb05f1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05481a5-366d-46bf-8b33-6d53ad2bfbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   ProfilerStep*         0.74%      10.425ms       100.00%        1.414s     141.414ms     210.21 Mb      -1.90 Gb            10            --  \n",
      "                      Conv block         5.81%      82.200ms        93.41%        1.321s       5.080ms       1.93 Gb           0 b           260            --  \n",
      "                    aten::conv2d         0.16%       2.284ms        61.98%     876.429ms       3.371ms     660.16 Mb           0 b           260    124452.864  \n",
      "               aten::convolution         0.40%       5.595ms        61.81%     874.144ms       3.362ms     660.16 Mb           0 b           260            --  \n",
      "              aten::_convolution         0.29%       4.092ms        61.42%     868.550ms       3.341ms     660.16 Mb           0 b           260            --  \n",
      "        aten::mkldnn_convolution        60.82%     860.136ms        61.13%     864.458ms       3.325ms     660.16 Mb           0 b           260            --  \n",
      "                     aten::empty         0.43%       6.011ms         0.43%       6.011ms       2.312us       1.29 Gb       1.29 Gb          2600            --  \n",
      "               aten::as_strided_         0.10%       1.472ms         0.10%       1.472ms       5.662us           0 b           0 b           260            --  \n",
      "                   aten::resize_         0.03%     438.900us         0.03%     438.900us       1.688us           0 b           0 b           260            --  \n",
      "                      aten::add_         0.28%       3.931ms         0.28%       3.931ms      15.119us           0 b           0 b           260            --  \n",
      "                aten::batch_norm         0.13%       1.786ms        19.84%     280.594ms       1.079ms     660.58 Mb           0 b           260            --  \n",
      "    aten::_batch_norm_impl_index         0.31%       4.430ms        19.72%     278.809ms       1.072ms     660.58 Mb           0 b           260            --  \n",
      "         aten::native_batch_norm        19.03%     269.090ms        19.37%     273.901ms       1.053ms     660.58 Mb    -865.00 Kb           260            --  \n",
      "                aten::empty_like         0.12%       1.688ms         0.16%       2.306ms       8.867us     660.16 Mb           0 b           260            --  \n",
      "                      aten::silu         5.50%      77.761ms         5.50%      77.761ms     299.082us     660.16 Mb     660.16 Mb           260            --  \n",
      "                       C2f block         0.93%      13.083ms        62.81%     888.227ms      22.206ms       1.36 Gb     -82.03 Mb            40            --  \n",
      "                     aten::chunk         0.02%     333.500us         0.16%       2.238ms      55.952us           0 b           0 b            40            --  \n",
      "                     aten::split         0.06%     828.200us         0.13%       1.905ms      47.615us           0 b           0 b            40            --  \n",
      "                    aten::narrow         0.08%       1.146ms         0.20%       2.895ms      13.159us           0 b           0 b           220            --  \n",
      "                     aten::slice         0.10%       1.398ms         0.12%       1.749ms       7.949us           0 b           0 b           220            --  \n",
      "                aten::as_strided         0.03%     383.200us         0.03%     383.200us       1.597us           0 b           0 b           240            --  \n",
      "                Bottleneck block         0.74%      10.513ms        33.17%     469.032ms       7.817ms     574.32 Mb           0 b            60            --  \n",
      "                       aten::add         0.95%      13.472ms         0.95%      13.472ms     224.540us      82.03 Mb      82.03 Mb            60        21.504  \n",
      "                       aten::cat         2.05%      29.028ms         2.18%      30.847ms     771.177us     199.22 Mb     199.22 Mb            40            --  \n",
      "                      ClassifyV8         0.12%       1.756ms         4.10%      57.961ms       5.796ms      39.25 Mb           0 b            10            --  \n",
      "        Adaptive Average Pooling         0.09%       1.225ms         0.25%       3.528ms     352.830us     -19.48 Mb     -19.53 Mb            10            --  \n",
      "       aten::adaptive_avg_pool2d         0.02%     283.100us         0.16%       2.303ms     230.330us      50.00 Kb           0 b            10            --  \n",
      "                      aten::mean         0.02%     273.500us         0.14%       2.020ms     202.020us      50.00 Kb      50.00 Kb            10            --  \n",
      "                       aten::sum         0.08%       1.174ms         0.09%       1.224ms     122.370us           0 b           0 b            10            --  \n",
      "                     aten::fill_         0.00%      50.100us         0.00%      50.100us       5.010us           0 b           0 b            10            --  \n",
      "                      aten::div_         0.01%     211.600us         0.04%     523.000us      52.300us           0 b         -40 b            10            --  \n",
      "                        aten::to         0.00%      50.600us         0.02%     311.400us      31.140us          40 b           0 b            10            --  \n",
      "                  aten::_to_copy         0.01%     135.500us         0.02%     260.800us      26.080us          40 b           0 b            10            --  \n",
      "             aten::empty_strided         0.00%      40.700us         0.00%      40.700us       4.070us          40 b          40 b            10            --  \n",
      "                     aten::copy_         0.01%     142.300us         0.01%     142.300us       7.115us           0 b           0 b            20            --  \n",
      "                         Flatten         0.04%     552.800us         0.05%     761.500us      76.150us           0 b           0 b            10            --  \n",
      "                   aten::flatten         0.01%      80.500us         0.01%     208.700us      20.870us           0 b           0 b            10            --  \n",
      "                      aten::view         0.01%     128.200us         0.01%     128.200us      12.820us           0 b           0 b            10            --  \n",
      "                    Linear layer         0.07%     982.600us         0.39%       5.459ms     545.920us      39.06 Kb           0 b            10            --  \n",
      "                    aten::linear         0.01%     168.000us         0.32%       4.477ms     447.660us      39.06 Kb           0 b            10            --  \n",
      "                         aten::t         0.01%      95.200us         0.01%     199.900us      19.990us           0 b           0 b            10            --  \n",
      "                 aten::transpose         0.01%      79.800us         0.01%     104.700us      10.470us           0 b           0 b            10            --  \n",
      "                     aten::addmm         0.28%       3.987ms         0.29%       4.109ms     410.870us      39.06 Kb      39.06 Kb            10        25.600  \n",
      "                    aten::expand         0.00%      49.600us         0.00%      57.500us       5.750us           0 b           0 b            10            --  \n",
      "              aten::resolve_conj         0.00%       6.900us         0.00%       6.900us       0.345us           0 b           0 b            20            --  \n",
      "                     Log Softmax         0.06%     895.800us         0.08%       1.144ms     114.350us           0 b     -39.06 Kb            10            --  \n",
      "               aten::log_softmax         0.00%      54.100us         0.02%     247.700us      24.770us      39.06 Kb           0 b            10            --  \n",
      "              aten::_log_softmax         0.01%     193.600us         0.01%     193.600us      19.360us      39.06 Kb      39.06 Kb            10            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.414s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU],\n",
    "                                    schedule=torch.profiler.schedule(wait=1, warmup=2, active=10, repeat=1),\n",
    "                                    on_trace_ready=torch.profiler.tensorboard_trace_handler('../log/darknet19/inference'),\n",
    "                                    record_shapes=True,\n",
    "                                    profile_memory=True,\n",
    "                                    with_flops=True,\n",
    "                                    with_modules=True,\n",
    "                                    with_stack=True) as prof:\n",
    "    for i in range(13):\n",
    "        out = model(img)\n",
    "        prof.step()\n",
    "print(prof.key_averages().table(row_limit=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7377cbfe-b6d4-4fd0-bad7-56e3d2b1e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_parallel(model):\n",
    "    \"\"\"De-parallelize a model: returns single-GPU model if model is of type DP or DDP.\"\"\"\n",
    "    return model.module if is_parallel(model) else model\n",
    "\n",
    "def is_parallel(model):\n",
    "    \"\"\"Returns True if model is of type DP or DDP.\"\"\"\n",
    "    return isinstance(model, (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8440ce1e-4b3b-4d35-8e5a-fed471527b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model, imgsz=640):\n",
    "    \"\"\"Return a YOLO model's FLOPs.\"\"\"\n",
    "    if not thop:\n",
    "        print('here')\n",
    "        return 0.0  # if not installed return 0.0 GFLOPs\n",
    "\n",
    "    model = de_parallel(model)\n",
    "    p = next(model.parameters())\n",
    "    if not isinstance(imgsz, list):\n",
    "        imgsz = [imgsz, imgsz]  # expand if int/float\n",
    "    try:\n",
    "        # Use stride size for input tensor\n",
    "        stride = max(int(model.stride.max()), 32) if hasattr(model, \"stride\") else 32  # max stride\n",
    "        im = torch.empty((1, p.shape[1], stride, stride), device=p.device).half()  # input image in BCHW format\n",
    "        flops = thop.profile(deepcopy(model), inputs=[im], verbose=False)[0] / 1e9 * 2  # stride GFLOPs\n",
    "        return flops * imgsz[0] / stride * imgsz[1] / stride  # imgsz GFLOPs\n",
    "    except Exception:\n",
    "        # Use actual image size for input tensor (i.e. required for RTDETR models)\n",
    "        im = torch.empty((1, p.shape[1], *imgsz), device=p.device)  # input image in BCHW format\n",
    "        return thop.profile(deepcopy(model), inputs=[im], verbose=False)[0] / 1e9 * 2  # imgsz GFLOPs\n",
    "\n",
    "\n",
    "def get_flops_with_torch_profiler(model, imgsz=640):\n",
    "    \"\"\"Compute model FLOPs (thop package alternative, but 2-10x slower unfortunately).\"\"\"\n",
    "    if not TORCH_2_0:  # torch profiler implemented in torch>=2.0\n",
    "        return 0.0\n",
    "    model = de_parallel(model)\n",
    "    p = next(model.parameters())\n",
    "    if not isinstance(imgsz, list):\n",
    "        imgsz = [imgsz, imgsz]  # expand if int/float\n",
    "    try:\n",
    "        # Use stride size for input tensor\n",
    "        stride = (max(int(model.stride.max()), 32) if hasattr(model, \"stride\") else 32) * 2  # max stride\n",
    "        im = torch.empty((1, p.shape[1], stride, stride), device=p.device)  # input image in BCHW format\n",
    "        with torch.profiler.profile(with_flops=True) as prof:\n",
    "            model(im)\n",
    "        flops = sum(x.flops for x in prof.key_averages()) / 1e9\n",
    "        flops = flops * imgsz[0] / stride * imgsz[1] / stride  # 640x640 GFLOPs\n",
    "    except Exception:\n",
    "        # Use actual image size for input tensor (i.e. required for RTDETR models)\n",
    "        im = torch.empty((1, p.shape[1], *imgsz), device=p.device)  # input image in BCHW format\n",
    "        with torch.profiler.profile(with_flops=True) as prof:\n",
    "            model(im)\n",
    "        flops = sum(x.flops for x in prof.key_averages()) / 1e9\n",
    "    return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3283ef84-d967-4379-bc08-0c2b202bb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_2_0 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3ccf277-ecf9-4c34-badd-86eba33deb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16d3e639-0243-4f5f-9d0c-46e6ce63f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88e8f48a-5bd8-4e7e-9388-c78b7cced2f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.HalfTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 36\u001b[0m, in \u001b[0;36mget_flops_with_torch_profiler\u001b[1;34m(model, imgsz)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(with_flops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m flops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x\u001b[38;5;241m.\u001b[39mflops \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m prof\u001b[38;5;241m.\u001b[39mkey_averages()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Half",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_flops_with_torch_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 43\u001b[0m, in \u001b[0;36mget_flops_with_torch_profiler\u001b[1;34m(model, imgsz)\u001b[0m\n\u001b[0;32m     41\u001b[0m     im \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39mimgsz), device\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# input image in BCHW format\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(with_flops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[1;32m---> 43\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     flops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x\u001b[38;5;241m.\u001b[39mflops \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m prof\u001b[38;5;241m.\u001b[39mkey_averages()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flops\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.HalfTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "get_flops_with_torch_profiler(model, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3729afa3-5658-4652-979e-aa09edf5a297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.609779199999998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flops(model, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "41449d2c-9f8f-4d4d-9403-e1d2deefa404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43be54c4-745c-4ea4-90f7-087365213e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../Models/yolov8s-cls.pt')['model'].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eafa0a83-5929-4535-80f1-7d11b329db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.609779199999998"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flops(model, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fa3dc54-a672-41e9-ad8d-7182ca35b079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ProfilerStep*',\n",
       " 'Conv block',\n",
       " 'aten::conv2d',\n",
       " 'aten::convolution',\n",
       " 'aten::_convolution',\n",
       " 'aten::mkldnn_convolution',\n",
       " 'aten::empty',\n",
       " 'aten::as_strided_',\n",
       " 'aten::resize_',\n",
       " 'aten::add_',\n",
       " 'aten::batch_norm',\n",
       " 'aten::_batch_norm_impl_index',\n",
       " 'aten::native_batch_norm',\n",
       " 'aten::empty_like',\n",
       " 'aten::silu',\n",
       " 'C2f block',\n",
       " 'aten::chunk',\n",
       " 'aten::split',\n",
       " 'aten::narrow',\n",
       " 'aten::slice',\n",
       " 'aten::as_strided',\n",
       " 'Bottleneck block',\n",
       " 'aten::add',\n",
       " 'aten::cat',\n",
       " 'ClassifyV8',\n",
       " 'Adaptive Average Pooling',\n",
       " 'aten::adaptive_avg_pool2d',\n",
       " 'aten::mean',\n",
       " 'aten::sum',\n",
       " 'aten::fill_',\n",
       " 'aten::div_',\n",
       " 'aten::to',\n",
       " 'aten::_to_copy',\n",
       " 'aten::empty_strided',\n",
       " 'aten::copy_',\n",
       " 'Flatten',\n",
       " 'aten::flatten',\n",
       " 'aten::view',\n",
       " 'Linear layer',\n",
       " 'aten::linear',\n",
       " 'aten::t',\n",
       " 'aten::transpose',\n",
       " 'aten::addmm',\n",
       " 'aten::expand',\n",
       " 'aten::resolve_conj',\n",
       " 'Log Softmax',\n",
       " 'aten::log_softmax',\n",
       " 'aten::_log_softmax']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.key for x in prof.key_averages()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ec8dc11-2083-4221-846b-c52cbea2aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add',\n",
       " 'count',\n",
       " 'cpu_children',\n",
       " 'cpu_memory_usage',\n",
       " 'cpu_parent',\n",
       " 'cpu_time',\n",
       " 'cpu_time_str',\n",
       " 'cpu_time_total',\n",
       " 'cpu_time_total_str',\n",
       " 'cuda_time',\n",
       " 'device_memory_usage',\n",
       " 'device_time',\n",
       " 'device_time_str',\n",
       " 'device_time_total',\n",
       " 'device_time_total_str',\n",
       " 'device_type',\n",
       " 'flops',\n",
       " 'input_shapes',\n",
       " 'is_async',\n",
       " 'is_legacy',\n",
       " 'is_remote',\n",
       " 'key',\n",
       " 'node_id',\n",
       " 'scope',\n",
       " 'self_cpu_memory_usage',\n",
       " 'self_cpu_time_total',\n",
       " 'self_cpu_time_total_str',\n",
       " 'self_device_memory_usage',\n",
       " 'self_device_time_total',\n",
       " 'self_device_time_total_str',\n",
       " 'stack',\n",
       " 'use_device']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(prof.key_averages()[0])[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bc18b823-a6fa-409a-96bc-b0d5a890acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29757.65,\n",
       " 973.3776923076921,\n",
       " 577.5357692307693,\n",
       " 569.7396153846147,\n",
       " 553.7823076923078,\n",
       " 528.9579166666668,\n",
       " 1.6539615384614361,\n",
       " 2.42124999999955,\n",
       " 1.0988461538458445,\n",
       " 6.551923076923146,\n",
       " 177.62576923076867,\n",
       " 172.66423076923076,\n",
       " 161.1023076923071,\n",
       " 7.619999999999774,\n",
       " 47.15846153846192,\n",
       " 4917.837500000002,\n",
       " 46.46500000000119,\n",
       " 40.69499999999889,\n",
       " 10.576363636363894,\n",
       " 6.216363636363287,\n",
       " 1.0820833333331317,\n",
       " 1817.6650000000004,\n",
       " 67.36499999999994,\n",
       " 130.67000000000394,\n",
       " 698.0399999999997,\n",
       " 690.7900000000016,\n",
       " 5.3799999999992,\n",
       " 2411.4100000000035,\n",
       " 195.11999999999972,\n",
       " 108.34000000000196,\n",
       " 102.61000000000058,\n",
       " 37.14000000000124,\n",
       " 3.8900000000059665,\n",
       " 45.59999999999964,\n",
       " 25.99999999999818,\n",
       " 21.109999999996944,\n",
       " 3.8899999999950525,\n",
       " 5.455000000001382,\n",
       " 70.36999999999352,\n",
       " 16.81999999999898,\n",
       " 490.44000000000597,\n",
       " 404.99999999999307,\n",
       " 18.250000000006914,\n",
       " 8.239999999998327,\n",
       " 373.4900000000045,\n",
       " 6.270000000001164,\n",
       " 0.4250000000009095,\n",
       " 97.12999999999738,\n",
       " 21.98000000000102,\n",
       " 16.150000000005093]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.cpu_time for x in prof.key_averages()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb51939-51ca-49c1-be0b-064ba897c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.darknet19 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3fe8b8f-0296-4c68-b8ac-ea4cbcb3b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19(num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19d0106f-85cc-4efe-bbee-4f918d8afbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.618206368"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flops(model, imgsz=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1c88eab6-4e4e-4bbe-98a1-194f804aa8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \\n                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \\n--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \\n                   ProfilerStep*         2.94%       8.735ms       100.00%     297.577ms      29.758ms       9.50 Mb    -255.63 Mb            10            --  \\n                      Conv block        14.37%      42.772ms        85.05%     253.078ms     973.378us     243.03 Mb           0 b           260            --  \\n                    aten::conv2d         0.68%       2.027ms        50.46%     150.159ms     577.536us      80.87 Mb           0 b           260     15245.476  \\n               aten::convolution         1.39%       4.149ms        49.78%     148.132ms     569.740us      80.87 Mb           0 b           260            --  \\n              aten::_convolution         1.03%       3.073ms        48.39%     143.983ms     553.782us      80.87 Mb           0 b           260            --  \\n        aten::mkldnn_convolution        42.04%     125.095ms        42.66%     126.950ms     528.958us      79.91 Mb           0 b           240            --  \\n                     aten::empty         1.45%       4.300ms         1.45%       4.300ms       1.654us     170.66 Mb     170.66 Mb          2600            --  \\n               aten::as_strided_         0.20%     581.100us         0.20%     581.100us       2.421us           0 b           0 b           240            --  \\n                   aten::resize_         0.10%     285.700us         0.10%     285.700us       1.099us     980.00 Kb     980.00 Kb           260            --  \\n                      aten::add_         0.57%       1.704ms         0.57%       1.704ms       6.552us           0 b           0 b           260            --  \\n                aten::batch_norm         0.43%       1.290ms        15.52%      46.183ms     177.626us      81.29 Mb           0 b           260            --  \\n    aten::_batch_norm_impl_index         0.90%       2.685ms        15.09%      44.893ms     172.664us      81.29 Mb           0 b           260            --  \\n         aten::native_batch_norm        12.65%      37.651ms        14.08%      41.887ms     161.102us      81.29 Mb    -865.00 Kb           260            --  \\n                aten::empty_like         0.48%       1.423ms         0.67%       1.981ms       7.620us      80.87 Mb           0 b           260            --  \\n                      aten::silu         4.12%      12.261ms         4.12%      12.261ms      47.158us      80.87 Mb      80.87 Mb           260            --  \\n                       C2f block         2.57%       7.651ms        66.11%     196.714ms       4.918ms     171.08 Mb     -10.05 Mb            40            --  \\n                     aten::chunk         0.08%     230.800us         0.62%       1.859ms      46.465us           0 b           0 b            40            --  \\n                     aten::split         0.23%     684.700us         0.55%       1.628ms      40.695us           0 b           0 b            40            --  \\n                    aten::narrow         0.32%     959.200us         0.78%       2.327ms      10.576us           0 b           0 b           220            --  \\n                     aten::slice         0.38%       1.138ms         0.46%       1.368ms       6.216us           0 b           0 b           220            --  \\n                aten::as_strided         0.09%     259.700us         0.09%     259.700us       1.082us           0 b           0 b           240            --  \\n                Bottleneck block         2.36%       7.037ms        36.65%     109.060ms       1.818ms      70.44 Mb           0 b            60            --  \\n                       aten::add         1.36%       4.042ms         1.36%       4.042ms      67.365us      10.05 Mb      10.05 Mb            60         2.634  \\n                       aten::cat         1.29%       3.843ms         1.76%       5.227ms     130.670us      24.40 Mb      24.40 Mb            40            --  \\n               aten::thnn_conv2d         0.05%     145.000us         4.69%      13.961ms     698.040us     980.00 Kb           0 b            20            --  \\n      aten::_slow_conv2d_forward         4.57%      13.585ms         4.64%      13.816ms     690.790us     980.00 Kb      -8.61 Mb            20            --  \\n                      aten::view         0.05%     161.400us         0.05%     161.400us       5.380us           0 b           0 b            30            --  \\n                      ClassifyV8         0.48%       1.417ms         8.10%      24.114ms       2.411ms       4.97 Mb           0 b            10            --  \\n        Adaptive Average Pooling         0.29%     867.800us         0.66%       1.951ms     195.120us      -2.34 Mb      -2.39 Mb            10            --  \\n       aten::adaptive_avg_pool2d         0.02%      57.300us         0.36%       1.083ms     108.340us      50.00 Kb           0 b            10            --  \\n                      aten::mean         0.07%     198.700us         0.34%       1.026ms     102.610us      50.00 Kb      49.99 Kb            10            --  \\n                       aten::sum         0.11%     332.500us         0.12%     371.400us      37.140us           0 b           0 b            10            --  \\n                     aten::fill_         0.01%      38.900us         0.01%      38.900us       3.890us           0 b           0 b            10            --  \\n                      aten::div_         0.07%     196.000us         0.15%     456.000us      45.600us           8 b         -32 b            10            --  \\n                        aten::to         0.02%      48.900us         0.09%     260.000us      26.000us          40 b           0 b            10            --  \\n                  aten::_to_copy         0.04%     115.000us         0.07%     211.100us      21.110us          40 b           0 b            10            --  \\n             aten::empty_strided         0.01%      38.900us         0.01%      38.900us       3.890us          40 b          40 b            10            --  \\n                     aten::copy_         0.04%     109.100us         0.04%     109.100us       5.455us           0 b           0 b            20            --  \\n                         Flatten         0.18%     535.500us         0.24%     703.700us      70.370us           0 b           0 b            10            --  \\n                   aten::flatten         0.02%      59.100us         0.06%     168.200us      16.820us           0 b           0 b            10            --  \\n                    Linear layer         0.29%     854.400us         1.65%       4.904ms     490.440us      39.06 Kb           0 b            10            --  \\n                    aten::linear         0.04%     132.600us         1.36%       4.050ms     405.000us      39.06 Kb           0 b            10            --  \\n                         aten::t         0.03%     100.100us         0.06%     182.500us      18.250us           0 b           0 b            10            --  \\n                 aten::transpose         0.02%      60.400us         0.03%      82.400us       8.240us           0 b           0 b            10            --  \\n                     aten::addmm         1.21%       3.612ms         1.26%       3.735ms     373.490us      39.06 Kb      39.06 Kb            10        25.600  \\n                    aten::expand         0.02%      54.100us         0.02%      62.700us       6.270us           0 b           0 b            10            --  \\n              aten::resolve_conj         0.00%       8.500us         0.00%       8.500us       0.425us           0 b           0 b            20            --  \\n                     Log Softmax         0.25%     751.500us         0.33%     971.300us      97.130us           0 b     -39.06 Kb            10            --  \\n               aten::log_softmax         0.02%      58.300us         0.07%     219.800us      21.980us      39.06 Kb           0 b            10            --  \\n              aten::_log_softmax         0.05%     161.500us         0.05%     161.500us      16.150us      39.06 Kb      39.06 Kb            10            --  \\n--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \\nSelf CPU time total: 297.577ms\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages().table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d54ce8a-acf6-4bfb-85a1-bdf0427bf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b40d1579-721e-492e-bc3f-32f9b8116f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732103673.845408"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c723e933-da42-4e39-ab5d-11859d95ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "131bb29e-5973-4634-93e3-ca6205cf927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf, tb, t = 0, 0, [0, 0, 0]  # dt forward, backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3315ec8e-dbb9-4311-b2cc-94ded1460091",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Darknet19(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cc77126-404a-4eb1-b8ec-4f64058dd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caa79317-a1c2-4832-af4e-f58c2a66dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf, tb, t = 0, 0, [0, 0, 0]  # dt forward, backward\n",
    "for _ in range(n):\n",
    "    t[0] = time.time()\n",
    "    y = m(x)\n",
    "    t[1] = time.time()\n",
    "    tf += (t[1] - t[0]) * 1000 / n  # ms per op forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efd3ed82-315e-40b2-ab8f-90d014afda22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405.64892292022705"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c27a3-450b-42aa-9acb-d16f4d3f5afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
