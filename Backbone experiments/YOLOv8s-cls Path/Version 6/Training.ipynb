{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04833633-3c8f-4d84-8869-c36d9a0cd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a0a4b-7479-40b1-abdd-1227b6940040",
   "metadata": {},
   "source": [
    "https://lernapparat.de/debug-device-assert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5258e5c-2fd1-45d6-bf25-96674d504f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9deb7c5-1256-4fdd-b447-69f25786c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b63379-9363-448e-b927-2231dbb097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from data_preprocessing import *\n",
    "from data_augmentation import *\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from Models.yolov8cls_path import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdae16b-4251-46a6-865b-bfa81a9a5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35628af8-5f33-4d45-8a3c-3ed52eac7ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': {'d': 0.34, 'w': 0.25, 'mc': 1024},\n",
       " 's': {'d': 0.34, 'w': 0.5, 'mc': 1024},\n",
       " 'm': {'d': 0.67, 'w': 0.75, 'mc': 768},\n",
       " 'l': {'d': 1.0, 'w': 1.0, 'mc': 512},\n",
       " 'xl': {'d': 1.0, 'w': 1.25, 'mc': 512}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9a44f5d-8396-4654-b118-82473d81ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes=10, \n",
    "              residual_connection=True, \n",
    "              CSP=True, \n",
    "              add_hidden=True,\n",
    "              classifyV8=True,\n",
    "              bottleneck=0.75, \n",
    "              variant='s', \n",
    "              device=device, \n",
    "              dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7a55ab-c490-4ed6-9c46-df61b5dee02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (conv2): Conv(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (c2f1): C2f(\n",
       "    (conv1): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (conv2): Conv(\n",
       "      (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (n_blocks): ModuleList(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv3): Conv(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (c2f2): C2f(\n",
       "    (conv1): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (conv2): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (n_blocks): ModuleList(\n",
       "      (0-1): 2 x Bottleneck(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv4): Conv(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (c2f3): C2f(\n",
       "    (conv1): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (conv2): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (n_blocks): ModuleList(\n",
       "      (0-1): 2 x Bottleneck(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Conv(\n",
       "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): SiLU()\n",
       "  )\n",
       "  (c2f4): C2f(\n",
       "    (conv1): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (conv2): Conv(\n",
       "      (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (n_blocks): ModuleList(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classify): ClassifyV8(\n",
       "    (conv): Conv(\n",
       "      (conv): Conv2d(512, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (linear): Linear(in_features=1280, out_features=10, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3c5dd0-ac5d-4cbb-8463-d9ebe0621f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../../datasets/imagenette2/'\n",
    "norms_path = os.path.join(data_path, 'norms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e608e517-6da7-41c7-b62d-81cca6aecf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = get_means(path=norms_path, train_loader=None)\n",
    "# stds = get_stds(path=norms_path, train_loader=None)\n",
    "norms = get_norms(path=norms_path, train_loader=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1567c205-e99f-4a93-ae7a-20a457c2eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = norms['means'], norms['stds']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4a012-f83a-495c-929b-939db6549642",
   "metadata": {},
   "source": [
    "\n",
    "Profiling your personal module \n",
    "https://pytorch.org/tutorials/beginner/profiler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61344e-ef51-4068-9304-62ac2f686ae7",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-prevent-overfitting/1902\n",
    "Right now, with my augmented dataset, at epoch 8, I am getting a testset Top1 accuracy of 45% but a trainset Top1 accuracy of 69%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a702f-1ae5-4573-a299-a90db5b87b7f",
   "metadata": {},
   "source": [
    "You should strongly consider data augmentation in some meaningful way. If you’re attempting to do classification then think about what augmentations might add useful information and help distinguish classes in your dataset. In one of my cases, introducing background variation increased recognition rate by over 50%. Basically, with small datasets there is too much overfitting so you want the network to learn real-world distinctions vs. irrelevant artifacts like backgrounds / shadows etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d4f81f6-3dfe-4256-8c57-66f92768ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.RandomResizedCrop((224, 224)),\n",
    "                                              Augmentation(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=means, std=stds)])\n",
    "transformations_val = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=means, std=stds)\n",
    "                                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f555ed4-dfcf-4f5f-9a71-3e40a7ea2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageNetSubset(path=data_path, train=True, transform=transformations, half=False, show=False)\n",
    "val_dataset = ImageNetSubset(path=data_path, train=False, transform=transformations_val, half=False, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae476e6-947b-46a5-bed5-729af9ee6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab049c64-2683-432e-acd7-e3494df498f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3846504-a142-444a-85cb-d8ab411cc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fb7d049-0696-4341-991c-9b3bfbb0ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daee47e0-df3f-4342-b462-ef2104f8a7ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-06 11:54:12.429210 Epoch 1 \n",
      "2025-04-06 11:54:38.788744 Batch 15 \n",
      "2025-04-06 11:54:41.716343 Batch 30 \n",
      "2025-04-06 11:54:44.280535 Batch 45 \n",
      "2025-04-06 11:54:46.990268 Batch 60 \n",
      "2025-04-06 11:54:50.194543 Batch 75 \n",
      "2025-04-06 11:54:54.048923 Batch 90 \n",
      "2025-04-06 11:54:57.789160 Batch 105 \n",
      "2025-04-06 11:55:01.573120 Batch 120 \n",
      "2025-04-06 11:55:04.941133 Batch 135 \n",
      "[Train] Accuracy: 24.237%, Loss per batch: 2.0781\n",
      "2025-04-06 11:55:24.841268 Batch 15 \n",
      "2025-04-06 11:55:26.882468 Batch 30 \n",
      "2025-04-06 11:55:29.020529 Batch 45 \n",
      "2025-04-06 11:55:31.040684 Batch 60 \n",
      "[Val] Accuracy: 31.4395%, loss per batch: 2.0123\n",
      "Epoch 1: SGD lr 0.0100 -> 0.0090\n",
      "2025-04-06 11:55:32.263981 Epoch 2 \n",
      "2025-04-06 11:55:48.229531 Batch 15 \n",
      "2025-04-06 11:55:51.000905 Batch 30 \n",
      "2025-04-06 11:55:53.473526 Batch 45 \n",
      "2025-04-06 11:55:56.081634 Batch 60 \n",
      "2025-04-06 11:55:59.303414 Batch 75 \n",
      "2025-04-06 11:56:02.413055 Batch 90 \n",
      "2025-04-06 11:56:05.267740 Batch 105 \n",
      "2025-04-06 11:56:07.460546 Batch 120 \n",
      "2025-04-06 11:56:10.517380 Batch 135 \n",
      "[Train] Accuracy: 35.7588%, Loss per batch: 1.8272\n",
      "2025-04-06 11:56:29.337978 Batch 15 \n",
      "2025-04-06 11:56:31.367653 Batch 30 \n",
      "2025-04-06 11:56:33.998518 Batch 45 \n",
      "2025-04-06 11:56:35.782748 Batch 60 \n",
      "[Val] Accuracy: 34.0382%, loss per batch: 1.9841\n",
      "Epoch 2: SGD lr 0.0090 -> 0.0081\n",
      "2025-04-06 11:56:36.852215 Epoch 3 \n",
      "2025-04-06 11:56:52.834185 Batch 15 \n",
      "2025-04-06 11:56:55.538999 Batch 30 \n",
      "2025-04-06 11:56:58.127377 Batch 45 \n",
      "2025-04-06 11:57:00.578907 Batch 60 \n",
      "2025-04-06 11:57:03.410227 Batch 75 \n",
      "2025-04-06 11:57:06.123587 Batch 90 \n",
      "2025-04-06 11:57:08.972454 Batch 105 \n",
      "2025-04-06 11:57:11.863257 Batch 120 \n",
      "2025-04-06 11:57:14.726973 Batch 135 \n",
      "[Train] Accuracy: 42.7711%, Loss per batch: 1.664\n",
      "2025-04-06 11:57:32.684572 Batch 15 \n",
      "2025-04-06 11:57:34.861969 Batch 30 \n",
      "2025-04-06 11:57:37.420026 Batch 45 \n",
      "2025-04-06 11:57:39.158534 Batch 60 \n",
      "[Val] Accuracy: 46.9554%, loss per batch: 1.5868\n",
      "Epoch 3: SGD lr 0.0081 -> 0.0073\n",
      "2025-04-06 11:57:40.178183 Epoch 4 \n",
      "2025-04-06 11:57:55.990261 Batch 15 \n",
      "2025-04-06 11:57:58.902724 Batch 30 \n",
      "2025-04-06 11:58:01.400943 Batch 45 \n",
      "2025-04-06 11:58:04.036116 Batch 60 \n",
      "2025-04-06 11:58:06.959106 Batch 75 \n",
      "2025-04-06 11:58:09.368013 Batch 90 \n",
      "2025-04-06 11:58:12.232397 Batch 105 \n",
      "2025-04-06 11:58:14.552939 Batch 120 \n",
      "2025-04-06 11:58:17.441145 Batch 135 \n",
      "[Train] Accuracy: 46.6786%, Loss per batch: 1.5438\n",
      "2025-04-06 11:58:35.250749 Batch 15 \n",
      "2025-04-06 11:58:37.349421 Batch 30 \n",
      "2025-04-06 11:58:39.632611 Batch 45 \n",
      "2025-04-06 11:58:41.316792 Batch 60 \n",
      "[Val] Accuracy: 49.758%, loss per batch: 1.4675\n",
      "Epoch 4: SGD lr 0.0073 -> 0.0066\n",
      "2025-04-06 11:58:42.311461 Epoch 5 \n",
      "2025-04-06 11:58:57.665695 Batch 15 \n",
      "2025-04-06 11:59:00.389107 Batch 30 \n",
      "2025-04-06 11:59:03.120576 Batch 45 \n",
      "2025-04-06 11:59:05.512673 Batch 60 \n",
      "2025-04-06 11:59:08.399164 Batch 75 \n",
      "2025-04-06 11:59:11.434731 Batch 90 \n",
      "2025-04-06 11:59:14.499235 Batch 105 \n",
      "2025-04-06 11:59:16.891425 Batch 120 \n",
      "2025-04-06 11:59:19.694833 Batch 135 \n",
      "[Train] Accuracy: 50.5756%, Loss per batch: 1.4373\n",
      "2025-04-06 11:59:39.687372 Batch 15 \n",
      "2025-04-06 11:59:41.798915 Batch 30 \n",
      "2025-04-06 11:59:44.623810 Batch 45 \n",
      "2025-04-06 11:59:46.926541 Batch 60 \n",
      "[Val] Accuracy: 50.3439%, loss per batch: 1.4874\n",
      "Epoch 5: SGD lr 0.0066 -> 0.0059\n",
      "2025-04-06 11:59:48.192195 Epoch 6 \n",
      "2025-04-06 12:00:05.548283 Batch 15 \n",
      "2025-04-06 12:00:08.403223 Batch 30 \n",
      "2025-04-06 12:00:10.950997 Batch 45 \n",
      "2025-04-06 12:00:13.682120 Batch 60 \n",
      "2025-04-06 12:00:16.690571 Batch 75 \n",
      "2025-04-06 12:00:19.649747 Batch 90 \n",
      "2025-04-06 12:00:21.937799 Batch 105 \n",
      "2025-04-06 12:00:24.874800 Batch 120 \n",
      "2025-04-06 12:00:27.772038 Batch 135 \n",
      "[Train] Accuracy: 53.0151%, Loss per batch: 1.3657\n",
      "2025-04-06 12:00:49.513567 Batch 15 \n",
      "2025-04-06 12:00:51.698550 Batch 30 \n",
      "2025-04-06 12:00:54.036071 Batch 45 \n",
      "2025-04-06 12:00:55.989498 Batch 60 \n",
      "[Val] Accuracy: 55.4395%, loss per batch: 1.2925\n",
      "Epoch 6: SGD lr 0.0059 -> 0.0053\n",
      "2025-04-06 12:00:57.147079 Epoch 7 \n",
      "2025-04-06 12:01:13.023090 Batch 15 \n",
      "2025-04-06 12:01:15.465133 Batch 30 \n",
      "2025-04-06 12:01:18.432001 Batch 45 \n",
      "2025-04-06 12:01:21.291013 Batch 60 \n",
      "2025-04-06 12:01:24.608298 Batch 75 \n",
      "2025-04-06 12:01:27.579719 Batch 90 \n",
      "2025-04-06 12:01:30.143946 Batch 105 \n",
      "2025-04-06 12:01:33.116630 Batch 120 \n",
      "2025-04-06 12:01:36.122085 Batch 135 \n",
      "[Train] Accuracy: 56.2467%, Loss per batch: 1.3051\n",
      "2025-04-06 12:01:58.088088 Batch 15 \n",
      "2025-04-06 12:02:00.248102 Batch 30 \n",
      "2025-04-06 12:02:02.659651 Batch 45 \n",
      "2025-04-06 12:02:04.752719 Batch 60 \n",
      "[Val] Accuracy: 57.8089%, loss per batch: 1.2486\n",
      "Epoch 7: SGD lr 0.0053 -> 0.0048\n",
      "2025-04-06 12:02:05.875652 Epoch 8 \n",
      "2025-04-06 12:02:23.407110 Batch 15 \n",
      "2025-04-06 12:02:26.155221 Batch 30 \n",
      "2025-04-06 12:02:29.319134 Batch 45 \n",
      "2025-04-06 12:02:32.453016 Batch 60 \n",
      "2025-04-06 12:02:35.637200 Batch 75 \n",
      "2025-04-06 12:02:38.654478 Batch 90 \n",
      "2025-04-06 12:02:41.174598 Batch 105 \n",
      "2025-04-06 12:02:43.591084 Batch 120 \n",
      "2025-04-06 12:02:46.569371 Batch 135 \n",
      "[Train] Accuracy: 58.9186%, Loss per batch: 1.2318\n",
      "2025-04-06 12:03:05.607922 Batch 15 \n",
      "2025-04-06 12:03:07.647377 Batch 30 \n",
      "2025-04-06 12:03:09.881359 Batch 45 \n",
      "2025-04-06 12:03:11.653232 Batch 60 \n",
      "[Val] Accuracy: 60.4586%, loss per batch: 1.1844\n",
      "Epoch 8: SGD lr 0.0048 -> 0.0043\n",
      "2025-04-06 12:03:12.651532 Epoch 9 \n",
      "2025-04-06 12:03:28.669575 Batch 15 \n",
      "2025-04-06 12:03:31.281255 Batch 30 \n",
      "2025-04-06 12:03:34.049050 Batch 45 \n",
      "2025-04-06 12:03:36.392560 Batch 60 \n",
      "2025-04-06 12:03:39.254031 Batch 75 \n",
      "2025-04-06 12:03:41.939631 Batch 90 \n",
      "2025-04-06 12:03:44.499783 Batch 105 \n",
      "2025-04-06 12:03:47.007025 Batch 120 \n",
      "2025-04-06 12:03:50.415775 Batch 135 \n",
      "[Train] Accuracy: 59.6895%, Loss per batch: 1.1981\n",
      "2025-04-06 12:04:09.554339 Batch 15 \n",
      "2025-04-06 12:04:11.514925 Batch 30 \n",
      "2025-04-06 12:04:14.064518 Batch 45 \n",
      "2025-04-06 12:04:16.021322 Batch 60 \n",
      "[Val] Accuracy: 59.949%, loss per batch: 1.2273\n",
      "Epoch 9: SGD lr 0.0043 -> 0.0039\n",
      "2025-04-06 12:04:17.168474 Epoch 10 \n",
      "2025-04-06 12:04:33.611402 Batch 15 \n",
      "2025-04-06 12:04:36.738351 Batch 30 \n",
      "2025-04-06 12:04:39.730204 Batch 45 \n",
      "2025-04-06 12:04:42.102863 Batch 60 \n",
      "2025-04-06 12:04:45.282574 Batch 75 \n",
      "2025-04-06 12:04:48.128671 Batch 90 \n",
      "2025-04-06 12:04:50.863824 Batch 105 \n",
      "2025-04-06 12:04:53.618328 Batch 120 \n",
      "2025-04-06 12:04:56.425372 Batch 135 \n",
      "[Train] Accuracy: 62.0551%, Loss per batch: 1.1385\n",
      "2025-04-06 12:05:15.747571 Batch 15 \n",
      "2025-04-06 12:05:17.768440 Batch 30 \n",
      "2025-04-06 12:05:20.073106 Batch 45 \n",
      "2025-04-06 12:05:22.032617 Batch 60 \n",
      "[Val] Accuracy: 69.2739%, loss per batch: 0.9554\n",
      "Epoch 10: SGD lr 0.0039 -> 0.0035\n"
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../../log/YOLOv8cls-version-6/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fa7035e-ebd2-42ab-86e4-9e5e198f6f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Backbone experiments\\YOLOv8s-cls Path\\Version 6\\../../..\\train.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(os.path.join(outputs_path, f\"state.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:05:23.500251 Epoch 11 \n",
      "2025-04-06 12:05:39.380942 Batch 15 \n",
      "2025-04-06 12:05:42.010033 Batch 30 \n",
      "2025-04-06 12:05:44.898517 Batch 45 \n",
      "2025-04-06 12:05:48.133070 Batch 60 \n",
      "2025-04-06 12:05:51.570162 Batch 75 \n",
      "2025-04-06 12:05:54.445288 Batch 90 \n",
      "2025-04-06 12:05:57.002434 Batch 105 \n",
      "2025-04-06 12:05:59.823867 Batch 120 \n",
      "2025-04-06 12:06:02.782670 Batch 135 \n",
      "[Train] Accuracy: 63.2802%, Loss per batch: 1.1053\n",
      "2025-04-06 12:06:22.531566 Batch 15 \n",
      "2025-04-06 12:06:24.516194 Batch 30 \n",
      "2025-04-06 12:06:26.724958 Batch 45 \n",
      "2025-04-06 12:06:28.471543 Batch 60 \n",
      "[Val] Accuracy: 64.6624%, loss per batch: 1.0502\n",
      "Epoch 11: SGD lr 0.0035 -> 0.0031\n",
      "2025-04-06 12:06:29.568195 Epoch 12 \n",
      "2025-04-06 12:06:45.653207 Batch 15 \n",
      "2025-04-06 12:06:48.683536 Batch 30 \n",
      "2025-04-06 12:06:51.500089 Batch 45 \n",
      "2025-04-06 12:06:54.339846 Batch 60 \n",
      "2025-04-06 12:06:57.212749 Batch 75 \n",
      "2025-04-06 12:06:59.932843 Batch 90 \n",
      "2025-04-06 12:07:02.732857 Batch 105 \n",
      "2025-04-06 12:07:05.291865 Batch 120 \n",
      "2025-04-06 12:07:07.955889 Batch 135 \n",
      "[Train] Accuracy: 64.8643%, Loss per batch: 1.0579\n",
      "2025-04-06 12:07:27.302269 Batch 15 \n",
      "2025-04-06 12:07:29.446563 Batch 30 \n",
      "2025-04-06 12:07:31.877440 Batch 45 \n",
      "2025-04-06 12:07:33.710543 Batch 60 \n",
      "[Val] Accuracy: 71.8726%, loss per batch: 0.8795\n",
      "Epoch 12: SGD lr 0.0031 -> 0.0028\n",
      "2025-04-06 12:07:34.819217 Epoch 13 \n",
      "2025-04-06 12:07:51.081391 Batch 15 \n",
      "2025-04-06 12:07:53.786181 Batch 30 \n",
      "2025-04-06 12:07:56.837244 Batch 45 \n",
      "2025-04-06 12:07:59.369856 Batch 60 \n",
      "2025-04-06 12:08:02.127867 Batch 75 \n",
      "2025-04-06 12:08:04.776816 Batch 90 \n",
      "2025-04-06 12:08:07.622436 Batch 105 \n",
      "2025-04-06 12:08:10.306550 Batch 120 \n",
      "2025-04-06 12:08:13.446511 Batch 135 \n",
      "[Train] Accuracy: 66.2161%, Loss per batch: 1.0222\n",
      "2025-04-06 12:08:32.171171 Batch 15 \n",
      "2025-04-06 12:08:34.105077 Batch 30 \n",
      "2025-04-06 12:08:36.424382 Batch 45 \n",
      "2025-04-06 12:08:38.122571 Batch 60 \n",
      "[Val] Accuracy: 71.8981%, loss per batch: 0.8745\n",
      "Epoch 13: SGD lr 0.0028 -> 0.0025\n",
      "2025-04-06 12:08:39.170853 Epoch 14 \n",
      "2025-04-06 12:08:55.314025 Batch 15 \n",
      "2025-04-06 12:08:58.244332 Batch 30 \n",
      "2025-04-06 12:09:00.721051 Batch 45 \n",
      "2025-04-06 12:09:03.452236 Batch 60 \n",
      "2025-04-06 12:09:06.310582 Batch 75 \n",
      "2025-04-06 12:09:09.187448 Batch 90 \n",
      "2025-04-06 12:09:11.696703 Batch 105 \n",
      "2025-04-06 12:09:14.605948 Batch 120 \n",
      "2025-04-06 12:09:17.726476 Batch 135 \n",
      "[Train] Accuracy: 66.5329%, Loss per batch: 0.9954\n",
      "2025-04-06 12:09:37.086815 Batch 15 \n",
      "2025-04-06 12:09:39.005214 Batch 30 \n",
      "2025-04-06 12:09:41.264198 Batch 45 \n",
      "2025-04-06 12:09:43.018534 Batch 60 \n",
      "[Val] Accuracy: 72.7643%, loss per batch: 0.8406\n",
      "Epoch 14: SGD lr 0.0025 -> 0.0023\n",
      "2025-04-06 12:09:44.070531 Epoch 15 \n",
      "2025-04-06 12:10:00.015887 Batch 15 \n",
      "2025-04-06 12:10:02.669573 Batch 30 \n",
      "2025-04-06 12:10:05.508664 Batch 45 \n",
      "2025-04-06 12:10:08.075978 Batch 60 \n",
      "2025-04-06 12:10:11.148071 Batch 75 \n",
      "2025-04-06 12:10:13.919505 Batch 90 \n",
      "2025-04-06 12:10:16.507108 Batch 105 \n",
      "2025-04-06 12:10:19.097699 Batch 120 \n",
      "2025-04-06 12:10:21.867176 Batch 135 \n",
      "[Train] Accuracy: 67.6629%, Loss per batch: 0.9815\n",
      "2025-04-06 12:10:41.257709 Batch 15 \n",
      "2025-04-06 12:10:43.108630 Batch 30 \n",
      "2025-04-06 12:10:45.294043 Batch 45 \n",
      "2025-04-06 12:10:47.095535 Batch 60 \n",
      "[Val] Accuracy: 71.1083%, loss per batch: 0.8937\n",
      "Epoch 15: SGD lr 0.0023 -> 0.0021\n",
      "2025-04-06 12:10:48.195046 Epoch 16 \n",
      "2025-04-06 12:11:04.851380 Batch 15 \n",
      "2025-04-06 12:11:07.494366 Batch 30 \n",
      "2025-04-06 12:11:10.980936 Batch 45 \n",
      "2025-04-06 12:11:13.981299 Batch 60 \n",
      "2025-04-06 12:11:16.964847 Batch 75 \n",
      "2025-04-06 12:11:19.749384 Batch 90 \n",
      "2025-04-06 12:11:22.489897 Batch 105 \n",
      "2025-04-06 12:11:25.154787 Batch 120 \n",
      "2025-04-06 12:11:28.399968 Batch 135 \n",
      "[Train] Accuracy: 68.1065%, Loss per batch: 0.9539\n",
      "2025-04-06 12:11:47.203468 Batch 15 \n",
      "2025-04-06 12:11:49.109569 Batch 30 \n",
      "2025-04-06 12:11:51.269081 Batch 45 \n",
      "2025-04-06 12:11:53.083781 Batch 60 \n",
      "[Val] Accuracy: 73.3503%, loss per batch: 0.8243\n",
      "Epoch 16: SGD lr 0.0021 -> 0.0019\n",
      "2025-04-06 12:11:54.161390 Epoch 17 \n",
      "2025-04-06 12:12:09.920447 Batch 15 \n",
      "2025-04-06 12:12:12.969530 Batch 30 \n",
      "2025-04-06 12:12:16.095108 Batch 45 \n",
      "2025-04-06 12:12:18.528144 Batch 60 \n",
      "2025-04-06 12:12:21.224350 Batch 75 \n",
      "2025-04-06 12:12:23.969932 Batch 90 \n",
      "2025-04-06 12:12:26.990058 Batch 105 \n",
      "2025-04-06 12:12:29.729462 Batch 120 \n",
      "2025-04-06 12:12:32.761348 Batch 135 \n",
      "[Train] Accuracy: 69.9335%, Loss per batch: 0.9237\n",
      "2025-04-06 12:12:51.474283 Batch 15 \n",
      "2025-04-06 12:12:53.416567 Batch 30 \n",
      "2025-04-06 12:12:55.779861 Batch 45 \n",
      "2025-04-06 12:12:57.563525 Batch 60 \n",
      "[Val] Accuracy: 74.8535%, loss per batch: 0.7742\n",
      "Epoch 17: SGD lr 0.0019 -> 0.0017\n",
      "2025-04-06 12:12:58.599452 Epoch 18 \n",
      "2025-04-06 12:13:14.576712 Batch 15 \n",
      "2025-04-06 12:13:17.585473 Batch 30 \n",
      "2025-04-06 12:13:20.359745 Batch 45 \n",
      "2025-04-06 12:13:22.812596 Batch 60 \n",
      "2025-04-06 12:13:25.486972 Batch 75 \n",
      "2025-04-06 12:13:28.133023 Batch 90 \n",
      "2025-04-06 12:13:30.708256 Batch 105 \n",
      "2025-04-06 12:13:33.102551 Batch 120 \n",
      "2025-04-06 12:13:35.925455 Batch 135 \n",
      "[Train] Accuracy: 69.4582%, Loss per batch: 0.9087\n",
      "2025-04-06 12:13:53.921614 Batch 15 \n",
      "2025-04-06 12:13:55.735776 Batch 30 \n",
      "2025-04-06 12:13:57.928428 Batch 45 \n",
      "2025-04-06 12:13:59.649997 Batch 60 \n",
      "[Val] Accuracy: 73.5541%, loss per batch: 0.8083\n",
      "Epoch 18: SGD lr 0.0017 -> 0.0015\n",
      "2025-04-06 12:14:00.674508 Epoch 19 \n",
      "2025-04-06 12:14:16.405445 Batch 15 \n",
      "2025-04-06 12:14:19.087249 Batch 30 \n",
      "2025-04-06 12:14:21.863414 Batch 45 \n",
      "2025-04-06 12:14:24.365424 Batch 60 \n",
      "2025-04-06 12:14:26.933639 Batch 75 \n",
      "2025-04-06 12:14:29.770620 Batch 90 \n",
      "2025-04-06 12:14:32.742635 Batch 105 \n",
      "2025-04-06 12:14:35.008681 Batch 120 \n",
      "2025-04-06 12:14:37.852688 Batch 135 \n",
      "[Train] Accuracy: 69.9018%, Loss per batch: 0.8927\n",
      "2025-04-06 12:14:56.043036 Batch 15 \n",
      "2025-04-06 12:14:57.924587 Batch 30 \n",
      "2025-04-06 12:15:00.069469 Batch 45 \n",
      "2025-04-06 12:15:01.897419 Batch 60 \n",
      "[Val] Accuracy: 75.1338%, loss per batch: 0.7502\n",
      "Epoch 19: SGD lr 0.0015 -> 0.0014\n",
      "2025-04-06 12:15:03.091242 Epoch 20 \n",
      "2025-04-06 12:15:19.095168 Batch 15 \n",
      "2025-04-06 12:15:21.859483 Batch 30 \n",
      "2025-04-06 12:15:24.587911 Batch 45 \n",
      "2025-04-06 12:15:27.880124 Batch 60 \n",
      "2025-04-06 12:15:30.993107 Batch 75 \n",
      "2025-04-06 12:15:33.742920 Batch 90 \n",
      "2025-04-06 12:15:36.325719 Batch 105 \n",
      "2025-04-06 12:15:38.699166 Batch 120 \n",
      "2025-04-06 12:15:41.600311 Batch 135 \n",
      "[Train] Accuracy: 71.4965%, Loss per batch: 0.8554\n",
      "2025-04-06 12:16:01.274391 Batch 15 \n",
      "2025-04-06 12:16:03.162077 Batch 30 \n",
      "2025-04-06 12:16:05.346249 Batch 45 \n",
      "2025-04-06 12:16:07.069555 Batch 60 \n",
      "[Val] Accuracy: 76.0%, loss per batch: 0.7313\n",
      "Epoch 20: SGD lr 0.0014 -> 0.0012\n"
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, \n",
    "                                loss_fn, scheduler, outputs_path='../../log/YOLOv8cls-version-6/training/', resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbcfe3f-53c8-4faf-bdad-2e1d34940199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New Python (GPU)",
   "language": "python",
   "name": "new_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
