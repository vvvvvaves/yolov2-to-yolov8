{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5258e5c-2fd1-45d6-bf25-96674d504f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9deb7c5-1256-4fdd-b447-69f25786c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b63379-9363-448e-b927-2231dbb097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from data_preprocessing import *\n",
    "from data_augmentation import *\n",
    "from Models.darknet19 import *\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdae16b-4251-46a6-865b-bfa81a9a5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a44f5d-8396-4654-b118-82473d81ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19(num_classes=10, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3c5dd0-ac5d-4cbb-8463-d9ebe0621f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../datasets/imagenette2/'\n",
    "norms_path = os.path.join(data_path, 'norms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e608e517-6da7-41c7-b62d-81cca6aecf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means are: [0.44969913363456726, 0.44868946075439453, 0.45163223147392273]\n",
      "stds are: [0.28648287057876587, 0.28796446323394775, 0.2865694761276245]\n"
     ]
    }
   ],
   "source": [
    "means = get_means(path=norms_path, train_loader=None)\n",
    "stds = get_stds(path=norms_path, train_loader=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "840c3bfd-3f57-4508-9834-fd0c87b7532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.RandomResizedCrop((224, 224)),\n",
    "                                              Augmentation(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=means, std=stds)])\n",
    "transformations_val = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=means, std=stds)\n",
    "                                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfaadddf-3f19-4b50-93b4-98cf177980fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageNetSubset(path=data_path, train=True, transform=transformations, half=False, show=False)\n",
    "val_dataset = ImageNetSubset(path=data_path, train=False, transform=transformations_val, half=False, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d356b0-68a7-44f8-bf1b-397f7889dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e72a95-3140-4c39-afd7-e64d63bd5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85cc427f-08e2-43c3-a496-6f1c967a2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40a8174-7e18-43aa-83fd-41a98bf6ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab25057-2897-45cf-867e-7fc1e4a401d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:46:05.408478 Epoch 1 \n",
      "2024-12-08 17:46:19.843921 Batch 15 \n",
      "2024-12-08 17:46:22.863686 Batch 30 \n",
      "2024-12-08 17:46:25.832661 Batch 45 \n",
      "2024-12-08 17:46:28.835159 Batch 60 \n",
      "2024-12-08 17:46:31.819038 Batch 75 \n",
      "2024-12-08 17:46:34.809809 Batch 90 \n",
      "2024-12-08 17:46:37.786949 Batch 105 \n",
      "2024-12-08 17:46:40.781802 Batch 120 \n",
      "2024-12-08 17:46:43.841550 Batch 135 \n",
      "[Train] Accuracy: 28.3134%, Loss per batch: 2.0235\n",
      "2024-12-08 17:47:00.778264 Batch 15 \n",
      "2024-12-08 17:47:02.594127 Batch 30 \n",
      "2024-12-08 17:47:04.702893 Batch 45 \n",
      "2024-12-08 17:47:06.643338 Batch 60 \n",
      "[Val] Accuracy: 29.5541%, loss per batch: 2.3512\n",
      "Epoch 1: SGD lr 0.0100 -> 0.0090\n",
      "2024-12-08 17:47:07.797083 Epoch 2 \n",
      "2024-12-08 17:47:22.502999 Batch 15 \n",
      "2024-12-08 17:47:25.440560 Batch 30 \n",
      "2024-12-08 17:47:28.443208 Batch 45 \n",
      "2024-12-08 17:47:31.474548 Batch 60 \n",
      "2024-12-08 17:47:34.710216 Batch 75 \n",
      "2024-12-08 17:47:38.205006 Batch 90 \n",
      "2024-12-08 17:47:41.580416 Batch 105 \n",
      "2024-12-08 17:47:45.481623 Batch 120 \n",
      "2024-12-08 17:47:50.192880 Batch 135 \n",
      "[Train] Accuracy: 38.9165%, Loss per batch: 1.762\n",
      "2024-12-08 17:48:10.573817 Batch 15 \n",
      "2024-12-08 17:48:12.406686 Batch 30 \n",
      "2024-12-08 17:48:14.813528 Batch 45 \n",
      "2024-12-08 17:48:16.734418 Batch 60 \n",
      "[Val] Accuracy: 33.4522%, loss per batch: 2.351\n",
      "Epoch 2: SGD lr 0.0090 -> 0.0081\n",
      "2024-12-08 17:48:17.875785 Epoch 3 \n",
      "2024-12-08 17:48:33.830824 Batch 15 \n",
      "2024-12-08 17:48:38.304218 Batch 30 \n",
      "2024-12-08 17:48:42.912879 Batch 45 \n",
      "2024-12-08 17:48:47.617457 Batch 60 \n",
      "2024-12-08 17:48:52.160531 Batch 75 \n",
      "2024-12-08 17:48:56.699371 Batch 90 \n",
      "2024-12-08 17:49:01.259851 Batch 105 \n",
      "2024-12-08 17:49:05.821630 Batch 120 \n",
      "2024-12-08 17:49:10.405299 Batch 135 \n",
      "[Train] Accuracy: 44.8516%, Loss per batch: 1.6186\n",
      "2024-12-08 17:49:29.048544 Batch 15 \n",
      "2024-12-08 17:49:30.896064 Batch 30 \n",
      "2024-12-08 17:49:33.077869 Batch 45 \n",
      "2024-12-08 17:49:35.104603 Batch 60 \n",
      "[Val] Accuracy: 44.2803%, loss per batch: 1.6135\n",
      "Epoch 3: SGD lr 0.0081 -> 0.0073\n",
      "2024-12-08 17:49:36.278445 Epoch 4 \n",
      "2024-12-08 17:49:52.302894 Batch 15 \n",
      "2024-12-08 17:49:56.963899 Batch 30 \n",
      "2024-12-08 17:50:01.667570 Batch 45 \n",
      "2024-12-08 17:50:06.469864 Batch 60 \n",
      "2024-12-08 17:50:11.167544 Batch 75 \n",
      "2024-12-08 17:50:15.814068 Batch 90 \n",
      "2024-12-08 17:50:20.457185 Batch 105 \n",
      "2024-12-08 17:50:24.991306 Batch 120 \n",
      "2024-12-08 17:50:29.564322 Batch 135 \n",
      "[Train] Accuracy: 49.2027%, Loss per batch: 1.4926\n",
      "2024-12-08 17:50:47.976203 Batch 15 \n",
      "2024-12-08 17:50:49.756818 Batch 30 \n",
      "2024-12-08 17:50:51.985729 Batch 45 \n",
      "2024-12-08 17:50:53.938540 Batch 60 \n",
      "[Val] Accuracy: 43.2866%, loss per batch: 1.8371\n",
      "Epoch 4: SGD lr 0.0073 -> 0.0066\n",
      "2024-12-08 17:50:55.076417 Epoch 5 \n",
      "2024-12-08 17:51:11.208232 Batch 15 \n",
      "2024-12-08 17:51:15.810972 Batch 30 \n",
      "2024-12-08 17:51:20.518068 Batch 45 \n",
      "2024-12-08 17:51:25.155382 Batch 60 \n",
      "2024-12-08 17:51:29.933033 Batch 75 \n",
      "2024-12-08 17:51:34.531865 Batch 90 \n",
      "2024-12-08 17:51:39.220678 Batch 105 \n",
      "2024-12-08 17:51:43.973677 Batch 120 \n",
      "2024-12-08 17:51:48.631400 Batch 135 \n",
      "[Train] Accuracy: 51.8006%, Loss per batch: 1.4356\n",
      "2024-12-08 17:52:07.222941 Batch 15 \n",
      "2024-12-08 17:52:08.972677 Batch 30 \n",
      "2024-12-08 17:52:11.145682 Batch 45 \n",
      "2024-12-08 17:52:13.114187 Batch 60 \n",
      "[Val] Accuracy: 58.7771%, loss per batch: 1.2463\n",
      "Epoch 5: SGD lr 0.0066 -> 0.0059\n",
      "2024-12-08 17:52:14.215792 Epoch 6 \n",
      "2024-12-08 17:52:30.203236 Batch 15 \n",
      "2024-12-08 17:52:34.904156 Batch 30 \n",
      "2024-12-08 17:52:39.555317 Batch 45 \n",
      "2024-12-08 17:52:44.093685 Batch 60 \n",
      "2024-12-08 17:52:48.598334 Batch 75 \n",
      "2024-12-08 17:52:53.106406 Batch 90 \n",
      "2024-12-08 17:52:57.683503 Batch 105 \n",
      "2024-12-08 17:53:02.267677 Batch 120 \n",
      "2024-12-08 17:53:06.898627 Batch 135 \n",
      "[Train] Accuracy: 54.2613%, Loss per batch: 1.3609\n",
      "2024-12-08 17:53:25.827364 Batch 15 \n",
      "2024-12-08 17:53:27.575761 Batch 30 \n",
      "2024-12-08 17:53:29.789918 Batch 45 \n",
      "2024-12-08 17:53:31.788898 Batch 60 \n",
      "[Val] Accuracy: 51.4904%, loss per batch: 1.4778\n",
      "Epoch 6: SGD lr 0.0059 -> 0.0053\n",
      "2024-12-08 17:53:32.919308 Epoch 7 \n",
      "2024-12-08 17:53:49.971027 Batch 15 \n",
      "2024-12-08 17:53:54.476671 Batch 30 \n",
      "2024-12-08 17:53:59.017623 Batch 45 \n",
      "2024-12-08 17:54:03.625462 Batch 60 \n",
      "2024-12-08 17:54:08.217622 Batch 75 \n",
      "2024-12-08 17:54:12.811106 Batch 90 \n",
      "2024-12-08 17:54:17.395911 Batch 105 \n",
      "2024-12-08 17:54:21.992965 Batch 120 \n",
      "2024-12-08 17:54:26.598457 Batch 135 \n",
      "[Train] Accuracy: 56.1517%, Loss per batch: 1.2945\n",
      "2024-12-08 17:54:45.181886 Batch 15 \n",
      "2024-12-08 17:54:46.942112 Batch 30 \n",
      "2024-12-08 17:54:49.245912 Batch 45 \n",
      "2024-12-08 17:54:51.178313 Batch 60 \n",
      "[Val] Accuracy: 56.8153%, loss per batch: 1.3014\n",
      "Epoch 7: SGD lr 0.0053 -> 0.0048\n",
      "2024-12-08 17:54:52.274614 Epoch 8 \n",
      "2024-12-08 17:55:08.494604 Batch 15 \n",
      "2024-12-08 17:55:13.116914 Batch 30 \n",
      "2024-12-08 17:55:17.887431 Batch 45 \n",
      "2024-12-08 17:55:22.518508 Batch 60 \n",
      "2024-12-08 17:55:27.173292 Batch 75 \n",
      "2024-12-08 17:55:31.730888 Batch 90 \n",
      "2024-12-08 17:55:36.313880 Batch 105 \n",
      "2024-12-08 17:55:41.003129 Batch 120 \n",
      "2024-12-08 17:55:45.638127 Batch 135 \n",
      "[Train] Accuracy: 58.116%, Loss per batch: 1.2535\n",
      "2024-12-08 17:56:04.211066 Batch 15 \n",
      "2024-12-08 17:56:06.304061 Batch 30 \n",
      "2024-12-08 17:56:08.526225 Batch 45 \n",
      "2024-12-08 17:56:10.484551 Batch 60 \n",
      "[Val] Accuracy: 60.3822%, loss per batch: 1.1729\n",
      "Epoch 8: SGD lr 0.0048 -> 0.0043\n",
      "2024-12-08 17:56:11.644131 Epoch 9 \n",
      "2024-12-08 17:56:27.667920 Batch 15 \n",
      "2024-12-08 17:56:32.533152 Batch 30 \n",
      "2024-12-08 17:56:37.327851 Batch 45 \n",
      "2024-12-08 17:56:41.948732 Batch 60 \n",
      "2024-12-08 17:56:46.615690 Batch 75 \n",
      "2024-12-08 17:56:51.162333 Batch 90 \n",
      "2024-12-08 17:56:55.735938 Batch 105 \n",
      "2024-12-08 17:57:00.366908 Batch 120 \n",
      "2024-12-08 17:57:05.012249 Batch 135 \n",
      "[Train] Accuracy: 59.7318%, Loss per batch: 1.2051\n",
      "2024-12-08 17:57:23.276426 Batch 15 \n",
      "2024-12-08 17:57:25.106124 Batch 30 \n",
      "2024-12-08 17:57:27.169228 Batch 45 \n",
      "2024-12-08 17:57:29.081557 Batch 60 \n",
      "[Val] Accuracy: 59.9745%, loss per batch: 1.1982\n",
      "Epoch 9: SGD lr 0.0043 -> 0.0039\n",
      "2024-12-08 17:57:30.213264 Epoch 10 \n",
      "2024-12-08 17:57:46.363014 Batch 15 \n",
      "2024-12-08 17:57:51.034601 Batch 30 \n",
      "2024-12-08 17:57:55.720032 Batch 45 \n",
      "2024-12-08 17:58:00.548846 Batch 60 \n",
      "2024-12-08 17:58:05.294560 Batch 75 \n",
      "2024-12-08 17:58:10.016046 Batch 90 \n",
      "2024-12-08 17:58:14.749777 Batch 105 \n",
      "2024-12-08 17:58:19.481744 Batch 120 \n",
      "2024-12-08 17:58:24.183487 Batch 135 \n",
      "[Train] Accuracy: 61.5271%, Loss per batch: 1.1555\n",
      "2024-12-08 17:58:42.711792 Batch 15 \n",
      "2024-12-08 17:58:44.460655 Batch 30 \n",
      "2024-12-08 17:58:46.541206 Batch 45 \n",
      "2024-12-08 17:58:48.549577 Batch 60 \n",
      "[Val] Accuracy: 63.0064%, loss per batch: 1.1085\n",
      "Epoch 10: SGD lr 0.0039 -> 0.0035\n"
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../log/darknet19/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7f490a-e00d-4d96-bd40-df7958480629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Me\\PJAIT\\Thesis\\Code\\yolov2-to-yolov8\\Backbone experiments\\Darknet19\\../..\\train.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(os.path.join(outputs_path, f\"state.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:58:50.076927 Epoch 11 \n",
      "2024-12-08 17:59:06.395768 Batch 15 \n",
      "2024-12-08 17:59:11.176429 Batch 30 \n",
      "2024-12-08 17:59:15.809725 Batch 45 \n",
      "2024-12-08 17:59:20.404581 Batch 60 \n",
      "2024-12-08 17:59:24.986545 Batch 75 \n",
      "2024-12-08 17:59:29.620367 Batch 90 \n",
      "2024-12-08 17:59:34.252686 Batch 105 \n",
      "2024-12-08 17:59:38.904536 Batch 120 \n",
      "2024-12-08 17:59:43.584828 Batch 135 \n",
      "[Train] Accuracy: 62.5937%, Loss per batch: 1.1256\n",
      "2024-12-08 18:00:02.256586 Batch 15 \n",
      "2024-12-08 18:00:04.070312 Batch 30 \n",
      "2024-12-08 18:00:06.376339 Batch 45 \n",
      "2024-12-08 18:00:08.294606 Batch 60 \n",
      "[Val] Accuracy: 64.3822%, loss per batch: 1.0676\n",
      "Epoch 11: SGD lr 0.0035 -> 0.0031\n",
      "2024-12-08 18:00:09.420463 Epoch 12 \n",
      "2024-12-08 18:00:25.636371 Batch 15 \n",
      "2024-12-08 18:00:30.172394 Batch 30 \n",
      "2024-12-08 18:00:34.738872 Batch 45 \n",
      "2024-12-08 18:00:39.236784 Batch 60 \n",
      "2024-12-08 18:00:43.808451 Batch 75 \n",
      "2024-12-08 18:00:48.407398 Batch 90 \n",
      "2024-12-08 18:00:53.029752 Batch 105 \n",
      "2024-12-08 18:00:57.683587 Batch 120 \n",
      "2024-12-08 18:01:02.381103 Batch 135 \n",
      "[Train] Accuracy: 64.9805%, Loss per batch: 1.0698\n",
      "2024-12-08 18:01:20.983128 Batch 15 \n",
      "2024-12-08 18:01:22.874672 Batch 30 \n",
      "2024-12-08 18:01:25.008723 Batch 45 \n",
      "2024-12-08 18:01:27.059521 Batch 60 \n",
      "[Val] Accuracy: 68.8408%, loss per batch: 0.953\n",
      "Epoch 12: SGD lr 0.0031 -> 0.0028\n",
      "2024-12-08 18:01:28.175938 Epoch 13 \n",
      "2024-12-08 18:01:44.478916 Batch 15 \n",
      "2024-12-08 18:01:49.046454 Batch 30 \n",
      "2024-12-08 18:01:53.707680 Batch 45 \n",
      "2024-12-08 18:01:58.255857 Batch 60 \n",
      "2024-12-08 18:02:02.936050 Batch 75 \n",
      "2024-12-08 18:02:07.556421 Batch 90 \n",
      "2024-12-08 18:02:12.265113 Batch 105 \n",
      "2024-12-08 18:02:16.998879 Batch 120 \n",
      "2024-12-08 18:02:21.810242 Batch 135 \n",
      "[Train] Accuracy: 65.8887%, Loss per batch: 1.0436\n",
      "2024-12-08 18:02:40.542439 Batch 15 \n",
      "2024-12-08 18:02:42.483473 Batch 30 \n",
      "2024-12-08 18:02:44.747131 Batch 45 \n",
      "2024-12-08 18:02:46.702112 Batch 60 \n",
      "[Val] Accuracy: 70.5732%, loss per batch: 0.8986\n",
      "Epoch 13: SGD lr 0.0028 -> 0.0025\n",
      "2024-12-08 18:02:47.834285 Epoch 14 \n",
      "2024-12-08 18:03:04.099169 Batch 15 \n",
      "2024-12-08 18:03:08.705277 Batch 30 \n",
      "2024-12-08 18:03:13.231966 Batch 45 \n",
      "2024-12-08 18:03:17.766079 Batch 60 \n",
      "2024-12-08 18:03:22.427384 Batch 75 \n",
      "2024-12-08 18:03:27.050636 Batch 90 \n",
      "2024-12-08 18:03:31.770850 Batch 105 \n",
      "2024-12-08 18:03:36.522883 Batch 120 \n",
      "2024-12-08 18:03:41.493360 Batch 135 \n",
      "[Train] Accuracy: 65.7831%, Loss per batch: 1.0266\n",
      "2024-12-08 18:04:00.282248 Batch 15 \n",
      "2024-12-08 18:04:02.051106 Batch 30 \n",
      "2024-12-08 18:04:04.291497 Batch 45 \n",
      "2024-12-08 18:04:06.186566 Batch 60 \n",
      "[Val] Accuracy: 72.9936%, loss per batch: 0.8269\n",
      "Epoch 14: SGD lr 0.0025 -> 0.0023\n",
      "2024-12-08 18:04:07.283069 Epoch 15 \n",
      "2024-12-08 18:04:23.848512 Batch 15 \n",
      "2024-12-08 18:04:28.578076 Batch 30 \n",
      "2024-12-08 18:04:33.395620 Batch 45 \n",
      "2024-12-08 18:04:38.298833 Batch 60 \n",
      "2024-12-08 18:04:43.056486 Batch 75 \n",
      "2024-12-08 18:04:47.767185 Batch 90 \n",
      "2024-12-08 18:04:52.605063 Batch 105 \n",
      "2024-12-08 18:04:57.282401 Batch 120 \n",
      "2024-12-08 18:05:01.960245 Batch 135 \n",
      "[Train] Accuracy: 67.6312%, Loss per batch: 0.9868\n",
      "2024-12-08 18:05:20.665877 Batch 15 \n",
      "2024-12-08 18:05:22.514817 Batch 30 \n",
      "2024-12-08 18:05:24.749269 Batch 45 \n",
      "2024-12-08 18:05:26.785513 Batch 60 \n",
      "[Val] Accuracy: 70.9554%, loss per batch: 0.8737\n",
      "Epoch 15: SGD lr 0.0023 -> 0.0021\n",
      "2024-12-08 18:05:27.958262 Epoch 16 \n",
      "2024-12-08 18:05:44.344559 Batch 15 \n",
      "2024-12-08 18:05:49.149185 Batch 30 \n",
      "2024-12-08 18:05:53.891047 Batch 45 \n",
      "2024-12-08 18:05:58.479045 Batch 60 \n",
      "2024-12-08 18:06:03.165226 Batch 75 \n",
      "2024-12-08 18:06:07.915731 Batch 90 \n",
      "2024-12-08 18:06:12.597734 Batch 105 \n",
      "2024-12-08 18:06:17.295182 Batch 120 \n",
      "2024-12-08 18:06:22.018624 Batch 135 \n",
      "[Train] Accuracy: 67.8847%, Loss per batch: 0.9724\n",
      "2024-12-08 18:06:40.626842 Batch 15 \n",
      "2024-12-08 18:06:42.304942 Batch 30 \n",
      "2024-12-08 18:06:44.498817 Batch 45 \n",
      "2024-12-08 18:06:46.383730 Batch 60 \n",
      "[Val] Accuracy: 71.4395%, loss per batch: 0.8641\n",
      "Epoch 16: SGD lr 0.0021 -> 0.0019\n",
      "2024-12-08 18:06:47.475030 Epoch 17 \n",
      "2024-12-08 18:07:04.093145 Batch 15 \n",
      "2024-12-08 18:07:08.839300 Batch 30 \n",
      "2024-12-08 18:07:13.442716 Batch 45 \n",
      "2024-12-08 18:07:18.034782 Batch 60 \n",
      "2024-12-08 18:07:22.673159 Batch 75 \n",
      "2024-12-08 18:07:27.314936 Batch 90 \n",
      "2024-12-08 18:07:32.039448 Batch 105 \n",
      "2024-12-08 18:07:36.854559 Batch 120 \n",
      "2024-12-08 18:07:41.616272 Batch 135 \n",
      "[Train] Accuracy: 69.1414%, Loss per batch: 0.9439\n",
      "2024-12-08 18:08:00.106941 Batch 15 \n",
      "2024-12-08 18:08:02.008066 Batch 30 \n",
      "2024-12-08 18:08:04.189239 Batch 45 \n",
      "2024-12-08 18:08:06.099884 Batch 60 \n",
      "[Val] Accuracy: 76.2293%, loss per batch: 0.7601\n",
      "Epoch 17: SGD lr 0.0019 -> 0.0017\n",
      "2024-12-08 18:08:07.224319 Epoch 18 \n",
      "2024-12-08 18:08:23.493965 Batch 15 \n",
      "2024-12-08 18:08:28.193882 Batch 30 \n",
      "2024-12-08 18:08:32.823595 Batch 45 \n",
      "2024-12-08 18:08:37.458530 Batch 60 \n",
      "2024-12-08 18:08:42.075520 Batch 75 \n",
      "2024-12-08 18:08:46.739454 Batch 90 \n",
      "2024-12-08 18:08:51.389034 Batch 105 \n",
      "2024-12-08 18:08:56.097157 Batch 120 \n",
      "2024-12-08 18:09:00.872543 Batch 135 \n",
      "[Train] Accuracy: 69.8595%, Loss per batch: 0.9246\n",
      "2024-12-08 18:09:19.567866 Batch 15 \n",
      "2024-12-08 18:09:21.364379 Batch 30 \n",
      "2024-12-08 18:09:23.776130 Batch 45 \n",
      "2024-12-08 18:09:25.743452 Batch 60 \n",
      "[Val] Accuracy: 73.3503%, loss per batch: 0.8093\n",
      "Epoch 18: SGD lr 0.0017 -> 0.0015\n",
      "2024-12-08 18:09:26.890325 Epoch 19 \n",
      "2024-12-08 18:09:43.208134 Batch 15 \n",
      "2024-12-08 18:09:47.989783 Batch 30 \n",
      "2024-12-08 18:09:52.621763 Batch 45 \n",
      "2024-12-08 18:09:57.292473 Batch 60 \n",
      "2024-12-08 18:10:02.032655 Batch 75 \n",
      "2024-12-08 18:10:06.714687 Batch 90 \n",
      "2024-12-08 18:10:11.411957 Batch 105 \n",
      "2024-12-08 18:10:16.241814 Batch 120 \n",
      "2024-12-08 18:10:21.080830 Batch 135 \n",
      "[Train] Accuracy: 70.6094%, Loss per batch: 0.8919\n",
      "2024-12-08 18:10:39.810225 Batch 15 \n",
      "2024-12-08 18:10:41.559704 Batch 30 \n",
      "2024-12-08 18:10:43.832967 Batch 45 \n",
      "2024-12-08 18:10:45.800407 Batch 60 \n",
      "[Val] Accuracy: 70.4968%, loss per batch: 0.9516\n",
      "Epoch 19: SGD lr 0.0015 -> 0.0014\n",
      "2024-12-08 18:10:46.951967 Epoch 20 \n",
      "2024-12-08 18:11:03.259883 Batch 15 \n",
      "2024-12-08 18:11:07.835897 Batch 30 \n",
      "2024-12-08 18:11:12.397163 Batch 45 \n",
      "2024-12-08 18:11:16.992713 Batch 60 \n",
      "2024-12-08 18:11:21.596584 Batch 75 \n",
      "2024-12-08 18:11:26.248241 Batch 90 \n",
      "2024-12-08 18:11:30.973800 Batch 105 \n",
      "2024-12-08 18:11:35.708252 Batch 120 \n",
      "2024-12-08 18:11:40.433842 Batch 135 \n",
      "[Train] Accuracy: 71.1902%, Loss per batch: 0.8754\n",
      "2024-12-08 18:11:59.581737 Batch 15 \n",
      "2024-12-08 18:12:01.390594 Batch 30 \n",
      "2024-12-08 18:12:03.536836 Batch 45 \n",
      "2024-12-08 18:12:05.502742 Batch 60 \n",
      "[Val] Accuracy: 76.7389%, loss per batch: 0.7367\n",
      "Epoch 20: SGD lr 0.0014 -> 0.0012\n"
     ]
    }
   ],
   "source": [
    "history, gradient_stats = train(epochs, train_loader, val_loader, model, optimizer, loss_fn, scheduler, outputs_path='../log/darknet19/training/', resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4030f1-bcd7-4d8b-bf3f-6f5548858b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New Python (GPU)",
   "language": "python",
   "name": "new_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
